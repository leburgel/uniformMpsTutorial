{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all necessary imports for this chapter\n",
    "using LinearAlgebra\n",
    "using TensorOperations\n",
    "using TensorKit\n",
    "using KrylovKit\n",
    "include(\"TutorialFunctions.jl\")\n",
    "using .TutorialFunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [Tangent-space methods for uniform matrix product states](https://doi.org/10.21468/SciPostPhysLectNotes.7)\n",
    "\n",
    "## 0. Tensors in Julia\n",
    "\n",
    "Throughout these tutorials we will make use of tensors as they usually appear throughout the physical sciences. Contrary to the Python tutorials where tensors are represented as plain numpy arrays, here we will not represent a tensor using a Julia `Base.Array` but rather make use of the `TensorMap` type exported by the Julia package [TensorKit.jl](https://github.com/Jutho/TensorKit.jl). In short, this package implements tensors as (multi)linear maps from a domain vectorspace to a codomain vectorspace. It provides all kinds of vector space operations (scalar multiplication, addition, norms and inner products), index operations (permutations) and linear algebra operations (multiplication, factorizations). In addition, tensor contractions can be performed using the `@tensor` macro from [TensorOperations.jl](https://github.com/Jutho/TensorOperations.jl).\n",
    "\n",
    "For a detailed explanation on how to define and work with `TensorMap`s we refer to the [TensorKit.jl documentation](https://jutho.github.io/TensorKit.jl/latest/). Here, we will disregard any intricacies related to internal symmetries by restricting ourselves to (complex) Cartesian vector spaces of the sake of simplicity. This allows us to be a little less strict in working with tensor indices and helps keep the exposition of the algorithms clear without getting lost in details which are less important for this tutorial (at the cost of a one-time warning from the TensorKit internals). Sometimes we will be able to use the simpler `Tensor` type to represent a general tensor, which behaves much like you would expect a familiar multidimensional array. However, some situations greatly benefit from explicitly considering a tensor as a map from some some set of indices to some other set of indices. This should become clear as you progress through the tutorials, and we have added extra explanations for these use cases where possible.\n",
    "\n",
    "## 1. Matrix product states in the thermodynamic limit\n",
    "\n",
    "### 1.1 Normalization\n",
    "\n",
    "We start by considering a uniform MPS in the thermodynamic limit, which is defined as \n",
    "$$\\left | \\Psi(A) \\right \\rangle = \\sum_{\\{i\\}} \\boldsymbol{v}_L^\\dagger \\left[ \\prod_{m\\in\\mathbb{Z}} A^{i_m} \\right] \\boldsymbol{v}_R \\left | \\{i\\} \\right \\rangle.$$\n",
    "\n",
    "Here, $\\boldsymbol{v}_L^\\dagger$ and $\\boldsymbol{v}_R$ represent boundary vectors at infinity and the $A^i$ are complex matrices of size $D \\times D$ for every entry of the index $i$. This allows for the interpretation of the object $A$ as a three-legged tensor of dimensions $D\\times d \\times D$, where we will refer to $D$ as the bond dimension and $d$ as the physical dimension. With this object and the diagrammatic language of tensor networks, we can represent the state as\n",
    "\n",
    "<center><img src=\"./img/umps.svg\" alt=\"MPSstate\"/></center>\n",
    "\n",
    "\n",
    "Thus, we initialize and represent a uniform MPS state using a single `TensorMap` with three indices as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns a random complex MPS tensor.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `D::Int`: bond dimension for MPS.\n",
    "- `d::Int`: physical dimension for MPS.\n",
    "\n",
    "### Returns\n",
    "\n",
    "`A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs, ordered left-bottom-right.\n",
    "\"\"\"\n",
    "function createMPS(D, d)\n",
    "    A = Tensor(randn, ComplexF64, ℝ^D ⊗ ℝ^d ⊗ ℝ^D)\n",
    "    return A\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, D = 3, 5\n",
    "A = createMPS(D, d)\n",
    "\n",
    "@assert A isa TensorMap{CartesianSpace} \"Generated MPS tensor should be a TensorMap with Cartesian indices.\"\n",
    "@assert map(i -> dim(space(A, i)), 1:numind(A)) == [D, d, D] \"Generated MPS tensor has incorrect shape.\"\n",
    "@assert storagetype(A) == Matrix{ComplexF64} \"MPS tensor should have complex values\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the central objects in any MPS calculation is the transfer matrix, defined in our case as\n",
    "\n",
    "<center><img src=\"./img/tm.svg\" alt=\"transfer matrix\" style=\"display=block; margin:auto\"/></center>\n",
    "\n",
    "This object corresponds to an operator acting on the space of $D \\times D$ matrices, and can be interpreted as a 4-leg tensor. We will use the following convention for ordering the legs:\n",
    "1. top left\n",
    "2. bottom left\n",
    "3. top right\n",
    "4. bottom right\n",
    "\n",
    "The transfer matrix can be shown to be a completely positive map, such that its leading eigenvalue is a positive number. This eigenvalue should be rescaled to one to ensure a proper normalization of the state in the thermodynamic limit. To perform this normalization, we must therefore find the left and right fixed points $l$ and $r$ which correspond to the largest eigenvalues of the eigenvalue equations\n",
    "\n",
    "<center><img src=\"./img/fixedPoints.svg\" alt=\"fixed points\"/></center>\n",
    "\n",
    "Normalizing the state then means rescaling the MPS tensor $A \\leftarrow A / \\sqrt{\\lambda}$. Additionally, we may fix the normalization of the eigenvectors by requiring that their trace is equal to one:\n",
    "\n",
    "<center><img src=\"./img/traceNorm.svg\" alt=\"norm\"/></center>\n",
    "\n",
    "With these properties in place, the norm of an MPS can be evaluated as\n",
    "\n",
    "<center><img src=\"./img/mpsNorm.svg\" alt=\"norm\"/></center>\n",
    "\n",
    "It can be readily seen that the infinite product of transfer matrices reduces to a projector onto the fixed points, so that the norm reduces to the overlap between the boundary vectors and the fixed points. Since there is no effect of the boundary vectors on the bulk properties of the MPS, we can always choose these such that MPS is properly normalized as $ \\left \\langle \\Psi(\\bar{A})\\middle | \\Psi(A) \\right \\rangle = 1$.\n",
    "\n",
    "One way of normalizing an MPS tensor is therefore by creating the transfer matrix as a `TensorMap`, and computing its leading eigenvectors and eigenvalues by interpreting it as an operator between sets of two indices depending on whether we want to compute the left of right fixed points. This can be done using the [`KrylovKit.eigsolve`](https://jutho.github.io/KrylovKit.jl/stable/man/eig/) method, which given a `TensorMap` and specified sets of 'left' and 'right' indices computes the eigenvectors and eigenvalues of the corresponding operator. Note that while the left and right fixed points $l$ and $r$ are naturally defined as (eigen)vectors, their normalization and positivity are more naturally characterized by interpreting them as matrices. Therefore, we will always interpret $l$ and $r$ as maps from their bottom to top and top to bottom indices respectively using the `TensorKit.permute` method on the vectors returned by `eigsolve`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Form the transfermatrix of an MPS.\n",
    "\n",
    "### Parameters\n",
    "\n",
    "`A::TensorMap`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "\n",
    "### Returns\n",
    "\n",
    "-`E::TensorMap{CartesianSpace}``: Transfer matrix tensor with 4 legs of dimension (D, D, D, D), ordered topLeft-bottomLeft-topRight-bottomRight.\n",
    "\"\"\"\n",
    "function createTransfermatrix(A)\n",
    "    @tensor E[-1 -2 -3 -4] := A[-1 1 -3] * A'[-2 1 -4]\n",
    "    return E\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Normalize an MPS tensor.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `Anew::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "\n",
    "### Complexity\n",
    "\n",
    "O(D^6) algorithm, diagonalizing (D^2, D^2) matrix.\n",
    "\"\"\"\n",
    "function normalizeMPS(A)\n",
    "    E = createTransfermatrix(A)\n",
    "\n",
    "    # calculate largest magnitude right eigenvalue by interpreting the transfer matrix as a\n",
    "    # linear map from its right indices to its left indices\n",
    "    vals, _ = eigsolve(E, (1, 2), (3, 4), 1, :LM)\n",
    "    nrm = vals[1]\n",
    "    Anew = A / sqrt(nrm)\n",
    "    \n",
    "    return Anew\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find left fixed point.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `l::TensorMap{CartesianSpace, 1, 1}`: left fixed point with 2 legs of dimension (D, D), ordered bottom-top.\n",
    "\n",
    "### Complexity\n",
    "\n",
    "O(D^6) algorithm, diagonalizing (D^2, D^2) matrix.\n",
    "\"\"\"\n",
    "function leftFixedPoint(A)\n",
    "    E = createTransfermatrix(A)\n",
    "    \n",
    "    # calculate largest magnitude left fixed point by interpreting the transfer matrix as a\n",
    "    # linear map from its left indices to its right indices\n",
    "    _, vecs, _ = eigsolve(E, (4, 3), (2, 1), 1, :LM)\n",
    "    l = permute(vecs[1], (1,), (2,)) # interpret vector as matrix\n",
    "    \n",
    "    # make left fixed point hermitian and positive semidefinite explicitly\n",
    "    tracel = tr(l)\n",
    "    l /= (tracel / abs(tracel)) # remove possible phase\n",
    "    l = (l + l') / 2 # force hermitian\n",
    "\n",
    "    return l\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find right fixed point.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `r::TensorMap{CartesianSpace, 1, 1}`: right fixed point with 2 legs of dimension (D, D), top-bottom.\n",
    "\n",
    "### Complexity\n",
    "\n",
    "O(D^6) algorithm, diagonalizing (D^2, D^2) matrix.\n",
    "\"\"\"\n",
    "function rightFixedPoint(A)\n",
    "    E = createTransfermatrix(A)\n",
    "    \n",
    "    # calculate largest magnitude right fixed point by interpreting the transfer matrix as a\n",
    "    # linear map from its right indices to its left indices\n",
    "    _, vecs, _ = eigsolve(E, (1, 2), (3, 4), 1, :LM)\n",
    "    r = permute(vecs[1], (1,), (2,)) # interpret vector as matrix\n",
    "    \n",
    "    # make right fixed point hermitian and positive semidefinite explicitly\n",
    "    tracer = tr(r)\n",
    "    r /= (tracer / abs(tracer)) # remove possible phase\n",
    "    r = (r + r') / 2 # force hermitian\n",
    "    \n",
    "    return r\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find normalized fixed points.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `l::TensorMap{CartesianSpace, 1, 1}`: left fixed point with 2 legs of dimension (D, D), bottom-top.\n",
    "- `r::TensorMap{CartesianSpace, 1, 1}`: right fixed point with 2 legs of dimension (D, D), top-bottom.\n",
    "\n",
    "### Complexity\n",
    "\n",
    "O(D^6) algorithm, diagonalizing (D^2, D^2) matrix.\n",
    "\"\"\"\n",
    "function fixedPoints(A)\n",
    "    l, r = leftFixedPoint(A), rightFixedPoint(A)\n",
    "    \n",
    "    # calculate trace\n",
    "    trace = tr(l * r)\n",
    "    \n",
    "    return l / trace, r\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then perform some simple checks to verify that these methods indeed return the properly normalized left and right fixed points. However, at this point, a remark regarding the use of the `@tensor` macro with `TensorMap`s is in order. As stated above, we explicitly construct $l$ and $r$ as `TensorMap`s of rank (1, 1). When working with `TensorMap`s with non-trivial codomain, it is often desirable to explicitly indicate this in the `@tensor` notation, both to avoid accidental space mismatches and to be more explicit about the nature of the tensors involved. This specification is done by adding a `;` between indices in the domain and the codomain, as illustrated below. We try to systematically adhere to this specification as we will naturally encounter more `TensorMap`s with non-trivial partitionings between domain and codomain, for example when considering canonical forms below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = normalizeMPS(A)\n",
    "l, r = fixedPoints(A)\n",
    "\n",
    "@assert l isa TensorMap{CartesianSpace, 1, 1} \"l should be a TensorMap of rank (1, 1)\"\n",
    "@assert r isa TensorMap{CartesianSpace, 1, 1} \"r should be a TensorMap of rank (1, 1)\"\n",
    "@assert l ≈ l' \"left fixed point should be hermitian!\"\n",
    "@assert r ≈ r' \"right fixed point should be hermitian!\"\n",
    "\n",
    "@tensor lp[-1; -2] := A[1 2 -2] * l[3; 1] * conj(A[3 2 -1])\n",
    "@tensor rp[-1; -2] := A[-1 2 1] * r[1; 3] * conj(A[-2 2 3])\n",
    "tracelr = tr(l * r)\n",
    "\n",
    "@assert l ≈ lp \"l should be a left fixed point!\"\n",
    "@assert r ≈ rp \"r should be a right fixed point!\"\n",
    "@assert abs(tracelr - 1) < 1e-12 \"Left and right fixed points should be trace normalized!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2 Gauge freedom\n",
    "While a given MPS tensor $A$ corresponds to a unique state $\\left | \\Psi(A) \\right \\rangle$, the converse is not true, as different tensors may give rise to the same state. This is easily seen by noting that the gauge transform\n",
    "\n",
    "<center><img src=\"img/gaugeTransform.svg\" alt=\"gauge transform\"></center>\n",
    "\n",
    "leaves the physical state invariant. We may use this freedom in parametrization to impose canonical forms on the MPS tensor $A$.\n",
    "\n",
    "We start by considering the *left-orthonormal form* of an MPS, which is defined in terms of a tensor $A_L$ that satisfies the condition\n",
    "\n",
    "<center><img src=\"img/leftOrth.svg\" alt=\"left orthonormal\"></center>\n",
    "\n",
    "We can find the gauge transform $L$ that brings $A$ into this form\n",
    "\n",
    "<center><img src=\"img/leftGauge.svg\" alt=\"left gauge\"></center>\n",
    "\n",
    "by decomposing the fixed point $l$ as $l = L^\\dagger L$, such that\n",
    "\n",
    "<center><img src=\"img/leftOrth2.svg\" alt=\"left orthonormal2\"></center>\n",
    "\n",
    "Note that this gauge choice still leaves room for unitary gauge transformations\n",
    "\n",
    "<center><img src=\"img/unitaryGauge.svg\" alt=\"unitary gauge\"></center>\n",
    "\n",
    "which can be used to bring the right fixed point $r$ into diagonal form. Similarly, we can find the gauge transform that brings $A$ into *right-orthonormal form*\n",
    "\n",
    "<center><img src=\"img/rightGauge.svg\" alt=\"right gauge\"></center>\n",
    "\n",
    "such that\n",
    "\n",
    "<center><img src=\"img/rightOrth.svg\" alt=\"right gauge\"></center>\n",
    "\n",
    "and the left fixed point $l$ is diagonal. This way of bringing a given MPS into canonical form by decomposing the corresponding transfer matrix fixed points can be implemented using the matrix square root `sqrt` for `TensorMap`s as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Transform A to left-orthonormal gauge.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `L::TensorMap{CartesianSpace, 1, 1}`: left gauge tensor with 2 legs of dimension (D, D), ordered left-right.\n",
    "- `Al::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right, left orthonormal.\n",
    "\n",
    "### Complexity\n",
    "\n",
    "O(D^6) algorithm, diagonalizing (D^2, D^2) matrix.\n",
    "\"\"\"\n",
    "function leftOrthonormalize(A, l=leftFixedPoint(A))\n",
    "    # decompose l = L' * L using matrix square root\n",
    "    L = sqrt(l)\n",
    "    \n",
    "    # apply gauge L to A\n",
    "    @tensor Al[-1 -2 -3] := L[-1; 1] * A[1 -2 2] * inv(L)[2; -3]\n",
    "\n",
    "    return L, Al\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Transform A to right-orthonormal gauge.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `R::TensorMap{CartesianSpace, 1, 1}`: right gauge tensor with 2 legs of dimension (D, D), ordered left-right.\n",
    "- `Ar::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right, right orthonormal.\n",
    "\n",
    "### Complexity\n",
    "\n",
    "O(D^6) algorithm, diagonalizing (D^2, D^2) matrix.\n",
    "\"\"\"\n",
    "function rightOrthonormalize(A, r=rightFixedPoint(A))\n",
    "    # decompose r = R * R' using matrix square root\n",
    "    R = sqrt(r)\n",
    "    \n",
    "    # apply gauge R to A\n",
    "    @tensor Ar[-1 -2 -3] := inv(R)[-1; 1] * A[1 -2 2] * R[2; -3]\n",
    "\n",
    "    return R, Ar\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, Al = leftOrthonormalize(A, l)\n",
    "R, Ar = rightOrthonormalize(A, r)\n",
    "\n",
    "@assert L isa TensorMap{CartesianSpace, 1, 1} \"L should be a TensorMap of rank (1, 1)\"\n",
    "@assert R isa TensorMap{CartesianSpace, 1, 1} \"R should be a TensorMap of rank (1, 1)\"\n",
    "@assert L' * L ≈ l \"Left gauge doesn't sqaure to l\"\n",
    "@assert R * R' ≈ r \"Right gauge doesn't square to r\"\n",
    "\n",
    "# check if left and right canonical tensors contract to the identity map\n",
    "@tensor Al_id[-1; -2] := Al[1 2 -2] * conj(Al[1 2 -1])\n",
    "@tensor Ar_id[-1; -2] := Ar[-1 1 2] * conj(Ar[-2 1 2])\n",
    "\n",
    "@assert Ar_id ≈ id(space(Ar, 1)) \"Ar not in right-orthonormal form\"\n",
    "@assert Al_id ≈ id(space(Al, 3)) \"Al not in left-orthonormal form\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can define a *mixed gauge* for the uniform MPS by choosing one site, the 'center site', and bringing all tensors to the left of it in the left-orthonormal form and all the tensors to the right of it in the right-orthonormal form. Defining a new tensor $A_C$ on the center site, we obtain the form\n",
    "\n",
    "<center><img src=\"img/mixedGauge.svg\" alt=\"right gauge\"></center>\n",
    "\n",
    "By contrast, the original representation using the same tensor at every site is commonly referred to as the *uniform gauge*. The mixed gauge has an intuitive interpretation. Defining $C = LR$, this tensor then implements the gauge transform that maps the left-orthonormal tensor to the right-orthonormal one, thereby defining the center-site tensor $A_C$:\n",
    "\n",
    "<center><img src=\"img/mixedGauge2.svg\" alt=\"right gauge\"></center>\n",
    "\n",
    "This relation is called the mixed gauge condition and allows us to freely move the center tensor $A_C$ through the MPS, linking the left- and right orthonormal tensors.\n",
    "\n",
    "Finally we may bring $C$ into diagonal form by performing a singular value decomposition $C = USV^\\dagger$ (which you can easily do using [`TensorKit.tsvd`](https://jutho.github.io/TensorKit.jl/latest/lib/tensors/#TensorKit.tsvd)) and absorbing $U$ and $V^\\dagger$ into the definition of $A_L$ and $A_R$ using the residual unitary gauge freedom\n",
    "\n",
    "<center><img src=\"img/diagC.svg\" alt=\"mixed gauge3\"></center>\n",
    "\n",
    "The mixed canonical form with a diagonal $C$ now allows to straightforwardly write down a Schmidt decomposition of the state across an arbitrary bond in the chain\n",
    "\n",
    "$$ \\left | \\Psi(A) \\right \\rangle = \\sum_{i=1}^{D} C_i \\left | \\Psi^i_L(A_L) \\right \\rangle \\otimes \\left | \\Psi^i_R(A_R) \\right \\rangle,$$\n",
    "\n",
    "where the states $\\left | \\Psi^i_L(A_L) \\right \\rangle$ and $\\left | \\Psi^i_R(A_R) \\right \\rangle$ are orthogonal states on half the lattice. The diagonal elements $C_i$ are exactly the Schmidt numbers of any bipartition of the MPS, and as such determine its bipartite entanglement entropy\n",
    "\n",
    "$$ S = -\\sum_i C_i^2 \\log(C_i^2) .$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bring MPS tensor into mixed gauge, such that -Al-C- = -C-Ar- = Ac.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `Al::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right, left orthonormal.\n",
    "- `Ac::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right, center gauge.\n",
    "- `Ar::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right, right orthonormal.\n",
    "- `C::TensorMap{CartesianSpace, 1, 1}`: center gauge tensor with 2 legs of dimension (D, D), ordered left-right, diagonal.\n",
    "\n",
    "### Complexity\n",
    "\n",
    "O(D^6) algorithm, diagonalizing (D^2, D^2) matrix.\n",
    "\"\"\"\n",
    "function mixedCanonical(A)\n",
    "\n",
    "    # Compute left and right orthonormal forms\n",
    "    L, Al = leftOrthonormalize(A)\n",
    "    R, Ar = rightOrthonormalize(A)\n",
    "    \n",
    "    # center matrix C is matrix multiplication of L and R\n",
    "    C = L * R\n",
    "    \n",
    "    # singular value decomposition to diagonalize C\n",
    "    U, C, V = tsvd(C, (1,), (2,))\n",
    "\n",
    "    # absorb corresponding unitaries in Al and Ar\n",
    "    @tensor Al[-1 -2 -3] = U'[-1; 1] * Al[1 -2 2] * U[2; -3]\n",
    "    @tensor Ar[-1 -2 -3] = V[-1; 1] * Ar[1 -2 2] * V'[2; -3]\n",
    "\n",
    "    # normalize center matrix\n",
    "    norm = tr(C * C')\n",
    "    C /= sqrt(norm)\n",
    "\n",
    "    # compute center MPS tensor\n",
    "    @tensor Ac[-1 -2 -3] := Al[-1 -2 1] * C[1; -3]\n",
    "\n",
    "    return Al, Ac, Ar, C\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the entanglement spectrum of an MPS.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `S::Vector{Float64}`: vector containing the singular values of the center matrix, representing the entanglement spectrum.\n",
    "- `entropy::Float64`: entanglement entropy across a leg.\n",
    "\"\"\"\n",
    "function entanglementSpectrum(A)\n",
    "    # go to mixed gauge\n",
    "    _, _, _, C = mixedCanonical(A)\n",
    "\n",
    "    # calculate entropy\n",
    "    S = diag(C[])\n",
    "    entropy = -sum(sum(s.^2 .* log.(s.^2) for s in S))\n",
    "    \n",
    "    return S, entropy\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that gauging is still correct\n",
    "Al, Ac, Ar, C = mixedCanonical(A)\n",
    "S, entropy = entanglementSpectrum(A)\n",
    "\n",
    "@tensor Ar_id[-1; -2] := Ar[-1 1 2] * conj(Ar[-2 1 2])\n",
    "@tensor Al_id[-1; -2] := Al[1 2 -2] * conj(Al[1 2 -1])\n",
    "@tensor LHS[-1 -2 -3] := Al[-1 -2 1] * C[1; -3]\n",
    "@tensor RHS[-1 -2 -3] := C[-1; 1] * Ar[1 -2 -3]\n",
    "\n",
    "@assert C isa TensorMap{CartesianSpace, 1, 1} \"C should be a TensorMap of rank (1, 1)\"\n",
    "@assert Ar_id ≈ id(space(Ar, 1)) \"Ar not in right-orthonormal form\"\n",
    "@assert Al_id ≈ id(space(Al, 3)) \"Al not in left-orthonormal form\"\n",
    "@assert LHS ≈ RHS && RHS ≈ Ac \"Something went wrong in gauging the MPS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.3 Truncation of a uniform MPS\n",
    "\n",
    "The mixed canonical form also enables efficient truncatation of an MPS. The sum in the above Schmidt decomposition can be truncated, giving rise to a new MPS that has a reduced bond dimension for that bond. This truncation is optimal in the sense that the norm between the original and the truncated MPS is maximized. To arrive at a translation invariant truncated MPS, we can truncate the columns of the absorbed isometries $U$ and $V^\\dagger$ correspondingly, thereby transforming *every* tensor $A_L$ or $A_R$. The truncated MPS in the mixed gauge is then given by\n",
    "\n",
    "<center><img src=\"img/truncMPS.svg\" alt=\"truncated MPS\"></center>\n",
    "\n",
    "We note that the resulting state based on this local truncation is not guaranteed to correspond to the MPS with a lower bond dimension that is globally optimal. This would require a variational optimization of the cost function.\n",
    "\n",
    "$$ \\left | \\left | ~\\left | \\Psi(A) \\right \\rangle - \\left | \\Psi(\\tilde{A}) \\right \\rangle ~\\right | \\right |^2.$$\n",
    "\n",
    "This truncation can be performed using the `trunc` keyword argument in [`TensorKit.tsvd`](https://jutho.github.io/TensorKit.jl/latest/lib/tensors/#TensorKit.tsvd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Truncate an MPS to a lower bond dimension.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `Ãl::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (Dtrunc, d, Dtrunc), ordered left-bottom-right, left orthonormal.\n",
    "- `Ãc::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (Dtrunc, d, Dtrunc), ordered left-bottom-right, center gauge.\n",
    "- `Ãr::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (Dtrunc, d, Dtrunc), ordered left-bottom-right, right orthonormal.\n",
    "- `C̃::TensorMap{CartesianSpace, 1, 1}`: center gauge tensor with 2 legs of dimension (Dtrunc, Dtrunc), ordered left-right, diagonal.\n",
    "\"\"\"\n",
    "function truncateMPS(A, Dtrunc)\n",
    "    Al, Ac, Ar, C = mixedCanonical(A)\n",
    "    \n",
    "    # perform SVD and truncate:\n",
    "    U, S, V = tsvd(C, (1,), (2,); trunc=truncdim(Dtrunc))\n",
    "    \n",
    "    # reabsorb unitaries\n",
    "    @tensor Ãl[-1 -2 -3] := U'[-1; 1] * Al[1 -2 2] * U[2; -3]\n",
    "    @tensor Ãr[-1 -2 -3] := V[-1; 1] * Ar[1 -2 2] * V'[2; -3]\n",
    "    C̃ = S\n",
    "    \n",
    "    # normalize center matrix\n",
    "    norm = tr(C̃ * C̃')\n",
    "    C̃ /= sqrt(norm)\n",
    "\n",
    "    # compute center MPS tensor\n",
    "    @tensor Ãc[-1 -2 -3] := Ãl[-1 -2 1] * C̃[1; -3]\n",
    "    \n",
    "    return Ãl, Ãc, Ãr, C̃\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtrunc = 3\n",
    "Ãl, Ãc, Ãr, C̃ = truncateMPS(A, Dtrunc)\n",
    "@assert dim(space(Ãl, 1)) == Dtrunc && dim(space(Ãl, 3)) == Dtrunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Algorithms for finding canonical forms\n",
    "The success of using MPS for describing physical systems stems from the fact that they provide efficient approximations to a large class of physically relevant states. In one dimension, they have been shown to approximate low-energy states of gapped systems arbitrarily well at only a polynomial cost in the bond dimension $D$. This means that in principle we can push MPS results for these systems to arbitrary precision as long as we increase the bond dimension enough. However, increasing the bond dimension comes at a numerical cost, as the complexity of any MPS algorithm scales with $D$. As opposed to the naive routines given above, it is possible to ensure that the complexity of all MPS algorithms scales as $O(D^3)$, so long as we are a bit careful when implementing them.\n",
    "\n",
    "As a first example, we can refrain from explicitly contructing the matrices that are used in the eigenvalue problems, and instead pass a function that implements the action of the corresponding operator on a vector to the eigenvalue solver. We demonstrate this for the problem of normalizing an MPS, where instead of explicitly constructing the transfer matrix we now provide a function which implements its action on the right and left fixed points using an optimal contraction sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Normalize an MPS tensor.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `Anew::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "\n",
    "### Complexity\n",
    "\n",
    "O(D^3) algorithm, D^3 contraction for transfer matrix handle.\n",
    "\"\"\"\n",
    "function normalizeMPS(A)\n",
    "    vals, _, _ =\n",
    "        eigsolve(TensorMap(randn, scalartype(A), space(A, 1) ← space(A, 1)), 1, :LM) do v\n",
    "            @tensor vout[-1; -2] := A[-1 2 1] * conj(A[-2 2 3]) * v[1; 3]\n",
    "        end\n",
    "\n",
    "    Anew = A / sqrt(vals[1])\n",
    "\n",
    "    return Anew\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find left fixed point.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `l::TensorMap{CartesianSpace, 1, 1}`: left fixed point with 2 legs of dimension (D, D), ordered bottom-top.\n",
    "\n",
    "### Complexity\n",
    "\n",
    "O(D^3) algorithm, D^3 contraction for transfer matrix handle.\n",
    "\"\"\"\n",
    "function leftFixedPoint(A)\n",
    "    # calculate fixed point\n",
    "    _, vecs, _ =\n",
    "        eigsolve(TensorMap(randn, scalartype(A), space(A, 1) ← space(A, 1)), 1, :LM) do v\n",
    "            @tensor vout[-1; -2] := A[1 2 -2] * conj(A[3 2 -1]) * v[3; 1]\n",
    "        end\n",
    "    l = vecs[1]\n",
    "    \n",
    "    # make left fixed point hermitian and positive semidefinite explicitly\n",
    "    tracel = tr(l)\n",
    "    l /= (tracel / abs(tracel)) # remove possible phase\n",
    "    l = (l + l') / 2 # force hermitian\n",
    "\n",
    "    return l\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find right fixed point.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `r::TensorMap{CartesianSpace, 1, 1}`: right fixed point with 2 legs of dimension (D, D), ordered top-bottom.\n",
    "\n",
    "### Complexity\n",
    "\n",
    "O(D^3) algorithm, D^3 contraction for transfer matrix handle.\n",
    "\"\"\"\n",
    "function rightFixedPoint(A)\n",
    "    # calculate fixed point\n",
    "    _, vecs, _ =\n",
    "        eigsolve(TensorMap(randn, scalartype(A), space(A, 1) ← space(A, 1)), 1, :LM) do v\n",
    "            @tensor vout[-1; -2] := A[-1 2 1] * conj(A[-2 2 3]) * v[1; 3]\n",
    "        end\n",
    "    r = vecs[1]\n",
    "    \n",
    "    # make right fixed point hermitian and positive semidefinite explicitly\n",
    "    tracer = tr(r)\n",
    "    r /= (tracer / abs(tracer)) # remove possible phase\n",
    "    r = (r + r') / 2 # force hermitian\n",
    "\n",
    "    return r\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find normalized fixed points.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `l::TensorMap{CartesianSpace, 1, 1}`: left fixed point with 2 legs of dimension (D, D), bottom-top.\n",
    "- `r::TensorMap{CartesianSpace, 1, 1}`: right fixed point with 2 legs of dimension (D, D), top-bottom.\n",
    "\n",
    "### Complexity\n",
    "\n",
    "O(D^3) algorithm, D^3 contraction for transfer matrix handle.\n",
    "\"\"\"\n",
    "function fixedPoints(A)\n",
    "    # find fixed points\n",
    "    l, r = leftFixedPoint(A), rightFixedPoint(A)\n",
    "\n",
    "    # calculate trace\n",
    "    trace = tr(l * r)\n",
    "\n",
    "    return l / trace, r\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = createMPS(D, d)\n",
    "A = normalizeMPS(A)\n",
    "l, r = fixedPoints(A)\n",
    "\n",
    "@assert l isa TensorMap{CartesianSpace, 1, 1} \"l should be a TensorMap of rank (1, 1)\"\n",
    "@assert r isa TensorMap{CartesianSpace, 1, 1} \"r should be a TensorMap of rank (1, 1)\"\n",
    "@assert l ≈ l' \"left fixed point should be hermitian!\"\n",
    "@assert r ≈ r' \"right fixed point should be hermitian!\"\n",
    "\n",
    "@tensor lp[-1; -2] := A[1 2 -2] * l[3; 1] * conj(A[3 2 -1])\n",
    "@tensor rp[-1; -2] := A[-1 2 1] * r[1; 3] * conj(A[-2 2 3])\n",
    "tracelr = tr(l * r)\n",
    "\n",
    "@assert l ≈ lp \"l should be a left fixed point!\"\n",
    "@assert r ≈ rp \"r should be a right fixed point!\"\n",
    "@assert abs(tracelr - 1) < 1e-12 \"Left and right fixed points should be trace normalized!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can similarly improve both the efficiency and accuracy of the routines bringing a given MPS into its mixed canonical form. While plugging in the more efficient ways of finding the left and right fixed point into the above `mixedCanonical` routine would reduce its complexity to $O(D^3)$, this algorithm would still be suboptimal in terms of numerical accuracy. This arises from the fact that, while $l$ and $r$ are theoretically known to be positive hermitian matrices, at least one of them will nevertheless have small eigenvalues, say of order $\\eta$, if the MPS is supposed to provide a good approximation to an actual state. In practice, $l$ and $r$ are determined using an iterative eigensolver and will only be accurate up to a specified tolerance $\\epsilon$. Upon taking the 'square roots' $L$ and $R$, the numerical precision will then decrease to $\\text{min}(\\sqrt{\\epsilon}, \\epsilon / \\sqrt{\\eta})$. Furthermore, gauge transforming $A$ with $L$ or $R$ requires the potentially ill-conditioned inversions of $L$ and $R$, and will typically yield $A_L$ and $A_R$ which violate the orthonormalization condition in the same order $\\epsilon/\\sqrt{\\eta}$. We can circumvent both these probelems by resorting to so-called *single-layer algorithms*. These are algorithms that only work on the level of the MPS tensors in the ket layer, and never consider operations for which contractions with the bra layer are needed. We now demonstrate such a single-layer algorithm for finding canonical forms.\n",
    "\n",
    "Suppose we are given an MPS tensor $A$, then from the above discussion we know that bringing it into left canonical form means finding a left-orthonormal tensor $A_L$ and a matrix $L$ such that $L A=A_L L$. The idea is then to solve this equation iteratively, where in every iteration\n",
    "\n",
    "1. we start from a matrix $L^{i}$\n",
    "2. we construct the tensor $L^{i}A$\n",
    "3. we take a QR decomposition to obtain $A_L^{i+1} L^{i+1} = L^{i}A$, and\n",
    "4. we take $L^{i+1}$ to the next iteration\n",
    "\n",
    "The QR decomposition is represented diagrammatically as\n",
    "\n",
    "<center><img src=\"img/qrStep.svg\" alt=\"QR step\"></center>\n",
    "\n",
    "This iterative procedure is bound to converge to a fixed point for which $L^{(i+1)}=L^{(i)}=L$ and $A_L$ is left orthonormal by construction:\n",
    "\n",
    "<center><img src=\"img/qrConv.svg\" alt=\"QR convergence\"></center>\n",
    "\n",
    "A similar procedure can be used to find a right-orthonormal tensor $A_R$ and a matrix $R$ such that $A R = R A_R$. It is important to note that the convergence of this procedure relies on the fact that the QR decomposition is unique, which is not actually the case in general. However, it can be made unique by imposing that the diagonal elements of the triangular matrix $R$ must be positive. This extra condition is automatically imposed by using the `TensorKit.leftorth` and `TensorKit.rightorth` routines using the keyword arguments `alg=QRpos()` and `alg=LQpos()` respectively.\n",
    "\n",
    "Finally, we note that using `TensorKit.leftorth` and `TensorKit.rightorth` in this way naturally gives the left isometry $A_L$ as a rank (2, 1) `TensorMap` and the right isometry $A_R$ as a rank (1, 2) `TensorMap`, contrary to the previous implementation where there was not really a natural partition between domain and codomain for $A_L$ and $A_R$. From here on out, we will therefore adhere to this natural partitioning and always take the rank of $A_L$ and $A_R$ into account explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Transform A to right-orthonormal gauge.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "- `R0::TensorMap{CartesianSpace, 1, 1}`: right gauge tensor with 2 legs of dimension (D, D), initial guess.\n",
    "- `tol::Float64=1e-14`: convergence criterium, `norm(R - Rnew) < tol`.\n",
    "- `maxIter::Int=1e5`: maximum amount of iterations.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `R::TensorMap{CartesianSpace, 1, 1}`: right gauge tensor with 2 legs of dimension (D, D), ordered left-right.\n",
    "- `Ar::TensorMap{CartesianSpace, 1, 2}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right, right orthonormal.\n",
    "\"\"\"\n",
    "function rightOrthonormalize(\n",
    "    A, R0=TensorMap(randn, scalartype(A), space(A, 1) ← space(A, 3)); tol=1e-14, maxIter=1e5\n",
    ")\n",
    "    tol = max(tol, 1e-14)\n",
    "    i = 1\n",
    "\n",
    "    # Normalize R0\n",
    "    R0 /= norm(R0)\n",
    "\n",
    "    # Initialize loop\n",
    "    @tensor Ai[-1 -2 -3] := A[-1 -2 1] * R0[1; -3]\n",
    "    R, Ar = rightorth(Ai, (1,), (2, 3); alg=LQpos())\n",
    "    R /= norm(R)\n",
    "    convergence = norm(R - R0)\n",
    "\n",
    "    # Decompose A*R until R converges\n",
    "    while convergence > tol\n",
    "        # calculate AR and decompose\n",
    "        @tensor Ai[-1 -2 -3] = A[-1 -2 1] * R[1; -3]\n",
    "        Rnew, Ar = rightorth(Ai, (1,), (2, 3); alg=LQpos())\n",
    "\n",
    "        # normalize new R\n",
    "        Rnew /= norm(Rnew)\n",
    "\n",
    "        # calculate convergence criterium\n",
    "        convergence = norm(Rnew - R)\n",
    "        R = Rnew\n",
    "\n",
    "        # check if iterations exceeds maxIter\n",
    "        if i > maxIter\n",
    "            println(\"Warning, right decomposition has not converged \", convergence)\n",
    "            break\n",
    "        end\n",
    "        i += 1\n",
    "    end\n",
    "\n",
    "    return R, Ar\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Transform A to left-orthonormal gauge.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "- `L0::TensorMap{CartesianSpace, 1, 1}`: left gauge tensor with 2 legs of dimension (D, D), initial guess.\n",
    "- `tol::Float64=1e-14`: convergence criterium, `norm(R - Rnew) < tol`.\n",
    "- `maxIter::Int=1e5`: maximum amount of iterations.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `L::TensorMap{CartesianSpace, 1, 1}`: left gauge tensor with 2 legs of dimension (D, D), ordered left-right.\n",
    "- `Al::TensorMap{CartesianSpace, 2, 1}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right, left orthonormal.\n",
    "\"\"\"\n",
    "function leftOrthonormalize(\n",
    "    A, L0=TensorMap(randn, scalartype(A), space(A, 1) ← space(A, 3)); tol=1e-14, maxIter=1e5\n",
    ")\n",
    "    tol = max(tol, 1e-14)\n",
    "    i = 1\n",
    "\n",
    "    # Normalize L0\n",
    "    L0 /= norm(L0)\n",
    "\n",
    "    # Initialize loop\n",
    "    @tensor Ai[-1 -2 -3] := L0[-1; 1] * A[1 -2 -3]\n",
    "    Al, L = leftorth(Ai, (1, 2), (3,); alg=QRpos())\n",
    "    L /= norm(L)\n",
    "    convergence = norm(L - L0)\n",
    "\n",
    "    # Decompose L*A until L converges\n",
    "    while convergence > tol\n",
    "        # calculate LA and decompose\n",
    "        @tensor Ai[-1 -2 -3] = L[-1; 1] * A[1 -2 -3]\n",
    "        Al, Lnew = leftorth(Ai, (1, 2), (3,); alg=QRpos())\n",
    "\n",
    "        # normalize new L\n",
    "        Lnew /= norm(Lnew)\n",
    "\n",
    "        # calculate convergence criterium\n",
    "        convergence = norm(Lnew - L)\n",
    "        L = Lnew\n",
    "\n",
    "        # check if iterations exceeds maxIter\n",
    "        if i > maxIter\n",
    "            println(\"Warning, left decomposition has not converged \", convergence)\n",
    "            break\n",
    "        end\n",
    "        i += 1\n",
    "    end\n",
    "    \n",
    "    return L, Al\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bring MPS tensor into mixed gauge, such that -Al-C- = -C-Ar- = Ac.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `Al::TensorMap{CartesianSpace, 2, 1}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right, left orthonormal.\n",
    "- `Ac::TensorMap{CartesianSpace, 2, 1}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right, center gauge.\n",
    "- `Ar::TensorMap{CartesianSpace, 1, 2}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right, right orthonormal.\n",
    "- `C::TensorMap{CartesianSpace, 1, 1}`: center gauge tensor with 2 legs of dimension (D, D), ordered left-right, diagonal.\n",
    "\n",
    "### Complexity\n",
    "\n",
    "O(D^3) algorithm.\n",
    "\"\"\"\n",
    "function mixedCanonical(\n",
    "    A;\n",
    "    L0=TensorMap(randn, scalartype(A), space(A, 1) ← space(A, 3)),\n",
    "    R0=TensorMap(randn, scalartype(A), space(A, 1) ← space(A, 3)),\n",
    "    tol=1e-14,\n",
    "    maxIter=1e5,\n",
    ")\n",
    "    tol = max(tol, 1e-14)\n",
    "\n",
    "    # Compute left and right orthonormal forms\n",
    "    L, Al = leftOrthonormalize(A, L0; tol, maxIter)\n",
    "    R, Ar = rightOrthonormalize(A, R0; tol, maxIter)\n",
    "\n",
    "    # center matrix C is matrix multiplication of L and R\n",
    "    C = L * R\n",
    "\n",
    "    # singular value decomposition to diagonalize C\n",
    "    U, C, V = tsvd(C, (1,), (2,))\n",
    "\n",
    "    # absorb corresponding unitaries in Al and Ar\n",
    "    @tensor Al[-1 -2; -3] = U'[-1; 1] * Al[1 -2; 2] * U[2; -3]\n",
    "    @tensor Ar[-1; -2 -3] = V[-1; 1] * Ar[1; -2 2] * V'[2; -3]\n",
    "\n",
    "    # normalize center matrix\n",
    "    norm = tr(C * C')\n",
    "    C /= sqrt(norm)\n",
    "\n",
    "    # compute center MPS tensor\n",
    "    @tensor Ac[-1 -2; -3] := Al[-1 -2; 1] * C[1; -3]\n",
    "\n",
    "    return Al, Ac, Ar, C\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Al, Ac, Ar, C = mixedCanonical(A)\n",
    "\n",
    "@assert Al isa TensorMap{CartesianSpace, 2, 1} \"Al should be a TensorMap of rank (2, 1)\"\n",
    "@assert Ac isa TensorMap{CartesianSpace, 2, 1} \"Ac should be a TensorMap of rank (2, 1)\"\n",
    "@assert Ar isa TensorMap{CartesianSpace, 1, 2} \"Ar should be a TensorMap of rank (1, 2)\"\n",
    "@assert C isa TensorMap{CartesianSpace, 1, 1} \"C should be a TensorMap of rank (1, 1)\"\n",
    "\n",
    "@tensor Ar_id[-1; -2] := Ar[-1; 1 2] * conj(Ar[-2; 1 2])\n",
    "@tensor Al_id[-1; -2] := Al[1 2; -2] * conj(Al[1 2; -1])\n",
    "@tensor LHS[-1 -2; -3] := Al[-1 -2; 1] * C[1; -3]\n",
    "@tensor RHS[-1 -2; -3] := C[-1; 1] * Ar[1; -2 -3]\n",
    "\n",
    "@assert Ar_id ≈ id(space(Ar, 1)) \"Ar not in right-orthonormal form\"\n",
    "@assert Al_id ≈ id(space(Al, 3)) \"Al not in left-orthonormal form\"\n",
    "@assert LHS ≈ RHS && RHS ≈ Ac \"Something went wrong in gauging the MPS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "For the remainder of this tutorial, keep in mind that you should always aim to reduce the complexity of your algorithm to $O(D^3)$ in order to keep the computational cost tractable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Computing expectation values \n",
    "Now that we have seen the different ways to parametrize a given MPS, namely the uniform gauge and the mixed gauge, we wish to use these to compute expectation values of an extensive operator:\n",
    "$$ O = \\frac{1}{\\mathbb{Z}} \\sum_{n \\in \\mathbb{Z}} O_n. $$\n",
    "\n",
    "If we assume that each $O_n$ acts on a single site and we are working with a properly normalized MPS, translation invariance dictates that the expectation value of $O$ is given by the contraction\n",
    "\n",
    "<center><img src=\"img/expVal.svg\" alt=\"Expectation value\"></center>\n",
    "\n",
    "In the uniform gauge, we can use the fixed points of the transfer matrix to contract everything to the left and to the right of the operator, such that we are left with the contraction\n",
    "\n",
    "<center><img src=\"img/expVal2.svg\" alt=\"Expectation value 2\"></center>\n",
    "\n",
    "In the mixed gauge, we can locate the center site where the operator is acting, and then contract everything to the left and right to the identity to arrive at the particularly simple expression\n",
    "\n",
    "<center><img src=\"img/expVal3.svg\" alt=\"Expectation value 3\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the expectation value of a 1-site operator in uniform gauge.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `O::TensorMap{CartesianSpace, 1, 1}`: single-site operator with 2 legs of dimension (d, d), ordered top-bottom.\n",
    "- `A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "- `fpts::Tuple=fixedPoints(A)`: left and right fixed points of transfermatrix, normalized.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `o::ComplexF64`: expectation value of `O`.\n",
    "\"\"\"\n",
    "function expVal1Uniform(O, A, fpts=fixedPoints(A))\n",
    "    l, r = fpts\n",
    "    # contract expectation value network\n",
    "    @tensor o = l[4 1] * r[3 6] * A[1 2 3] * conj(A[4 5 6]) * O[2; 5]\n",
    "\n",
    "    return o\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the expectation value of a 1-site operator in mixed gauge.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `O::TensorMap{CartesianSpace, 1, 1}`: single-site operator with 2 legs of dimension (d, d), ordered top-bottom.\n",
    "- `Ac::TensorMap{CartesianSpace, 2, 1}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right, center gauged.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `o::ComplexF64`: expectation value of `O`.\n",
    "\"\"\"\n",
    "function expVal1Mixed(O, Ac)\n",
    "    # contract expectation value network\n",
    "    @tensor o = Ac[2 1; 3] * conj(Ac[2 4; 3]) * O[1; 4]\n",
    "\n",
    "    return o\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = TensorMap(randn, ComplexF64, ℝ^d ← ℝ^d)\n",
    "A = createMPS(D, d)\n",
    "A = normalizeMPS(A)\n",
    "Al, Ac, Ar, C = mixedCanonical(A)\n",
    "expVal = expVal1Uniform(O, A)\n",
    "expValMix = expVal1Mixed(O, Ac)\n",
    "diff = abs(expVal - expValMix)\n",
    "@assert diff < 1e-12 \"different gauges give different values?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This procedure can be readily generalized to operators that act on multiple sites. In particular, a two-site operator such as a Hamiltonian term $h$ can be evaluated as\n",
    "\n",
    "<center><img src=\"img/expValHam.svg\" alt=\"Expectation value Hamiltonian\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the expectation value of a 2-site operator in uniform gauge.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `O::TensorMap{CartesianSpace, 2, 2}`: two-site operator with 4 legs of dimension (d, d, d, d), ordered topLeft-topRight-bottomLeft-bottomRight.\n",
    "- `A::TensorMap{CartesianSpace}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right.\n",
    "- `fpts::Tuple=fixedPoints(A)`: left and right fixed points of transfermatrix, normalized.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `o::ComplexF64`: expectation value of `O`.\n",
    "\"\"\"\n",
    "function expVal2Uniform(O, A, fpts=fixedPoints(A))\n",
    "    l, r = fpts\n",
    "    # contract expectation value network\n",
    "    @tensor o = l[6; 1] * r[5; 10] * A[1 2 3] * A[3 4 5] * conj(A[6 7 8]) * conj(A[8 9 10]) * O[2 4; 7 9]\n",
    "\n",
    "    return o\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the expectation value of a 2-site operator in mixed gauge.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `O::TensorMap{CartesianSpace, 2, 2}`: two-site operator with 4 legs of dimension (d, d, d, d), ordered topLeft-topRight-bottomLeft-bottomRight.\n",
    "- `Ac::TensorMap{CartesianSpace, 2, 1}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right, center gauged.\n",
    "- `Ar::TensorMap{CartesianSpace, 1, 2}`: MPS tensor with 3 legs of dimension (D, d, D), ordered left-bottom-right, right gauged.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `o::ComplexF64`: expectation value of `O`.\n",
    "\"\"\"\n",
    "function expVal2Mixed(O, Ac, Ar)\n",
    "    # contract expectation value network\n",
    "    @tensor o = Ac[4 2; 1] * Ar[1; 3 6] * conj(Ac[4 5; 8]) * conj(Ar[8; 7 6]) * O[2 3; 5 7]\n",
    "\n",
    "    return o\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O2 = TensorMap(randn, ComplexF64, ℝ^d ⊗ ℝ^d ← ℝ^d ⊗ ℝ^d)\n",
    "\n",
    "expVal = expVal2Uniform(O2, A)\n",
    "expValGauge = expVal2Mixed(O2, Ac, Ar)\n",
    "expValGauge2 = expVal2Mixed(O2, Al, Ac)\n",
    "\n",
    "diff1 = abs(expVal - expValGauge)\n",
    "diff2 = abs(expVal - expValGauge2)\n",
    "@assert diff1 < 1e-12 && diff2 < 1e-12 \"different gauges give different values?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Julia 1.9.1",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
