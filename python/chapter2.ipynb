{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all necessary imports for this chapter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ncon import ncon\n",
    "from scipy.optimize import minimize\n",
    "from scipy.sparse.linalg import eigs, LinearOperator, gmres\n",
    "from scipy.linalg import svd, polar, null_space\n",
    "from functools import partial\n",
    "from time import time\n",
    "from tutorialFunctions import createMPS, normalizeMPS, fixedPoints, rightOrthonormalize, mixedCanonical, expVal2Uniform, expVal2Mixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Tangent-space methods for uniform matrix product states](https://doi.org/10.21468/SciPostPhysLectNotes.7)\n",
    "\n",
    "## 2. Finding ground states of local Hamiltonians\n",
    "\n",
    "In the previous chapter, we stated that uniform MPS can be used to efficiently approximate low-energy states of one-dimensional systems with gapped local Hamiltonians. Having defined ways of representing and manipulating MPS, the logical next step is therefore to have a look at how exactly they can be used to find ground states. To this end, we consider a nearest-neighbour Hamiltonian $H$  of the form\n",
    "\n",
    "$$H = \\sum_n h_{n, n+1}$$\n",
    "\n",
    "acting on an infinite one-dimensional system. Here, $h_{n,n+1}$ is a hermitian operator acting non-trivially on sites $n$ and $n+1$. As in any variational approach, the variational principle serves as a guide for finding ground-state approximations, dictating that the optimal MPS approximation of the ground state corresponds to the minimum of the expectation value of the energy,\n",
    "\n",
    "$$ \\min_A \\frac{\\left \\langle \\Psi(\\bar{A}) \\middle | H  \\middle | \\Psi(A) \\right \\rangle}{\\left \\langle \\Psi(\\bar{A}) \\middle | \\Psi(A)  \\right \\rangle}. $$\n",
    "\n",
    "In the thermodynamic limit the energy diverges with system size, but, since we are working with translation-invariant states only, we should rather minimize the energy density. In the following we will always restrict our discussion to preoperly normalized states. Diagrammatically, the minimization problem can then be recast as\n",
    "\n",
    "<center><img src=\"img/2minham.svg\" alt=\"minimization of hamiltonian\"></center>\n",
    "\n",
    "In this notebook we illustratre numerical optimization strategies for minimizing this energy density directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 The gradient\n",
    "\n",
    "Any optimization problem relies on an efficient evaluation of the gradient, so the first thing to do is to compute this quantity. The objective function $f$ that we want to minimize is a real function of the complex-valued $A$, or equivalently, of the independent variables $A$ and $\\bar{A}$. The gradient $g$ is then obtained by differentiating $f(\\bar{A},A)$ with respect to $\\bar{A}$,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "g &= 2 \\times \\frac{\\partial f(\\bar{A},A) }{ \\partial \\bar{A} } \\\\\n",
    "&= 2\\times \\frac{\\partial_{\\bar{A}} \\left \\langle \\Psi(\\bar{A}) \\middle | h  \\middle | \\Psi(A) \\right \\rangle } {\\left \\langle \\Psi(\\bar{A}) \\middle | \\Psi(A)  \\right \\rangle} - 2\\times \\frac{\\left \\langle \\Psi(\\bar{A}) \\middle | h  \\middle | \\Psi(A) \\right \\rangle} {\\left \\langle \\Psi(\\bar{A}) \\middle | \\Psi(A)  \\right \\rangle^2} \\partial_{\\bar{A}} \\left \\langle \\Psi(\\bar{A}) \\middle | \\Psi(A) \\right \\rangle ,\\\\\n",
    "&= 2\\times \\frac{\\partial_{\\bar{A}}  \\left \\langle \\Psi(\\bar{A}) \\middle | h  \\middle | \\Psi(A) \\right \\rangle - e \\partial_{\\bar{A}} \\left \\langle \\Psi(\\bar{A}) \\middle | \\Psi(A)  \\right \\rangle  } {\\left \\langle \\Psi(\\bar{A}) \\middle | \\Psi(A)  \\right \\rangle},\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where we have clearly indicated $A$ and $\\bar{A}$ as independent variables and $e$ is the current energy density given by\n",
    "\n",
    "$$\n",
    "e = \\frac{\\left \\langle \\Psi(\\bar{A}) \\middle | h  \\middle | \\Psi(A) \\right \\rangle} {\\left \\langle \\Psi(\\bar{A}) \\middle | \\Psi(A)  \\right \\rangle}.\n",
    "$$\n",
    "\n",
    "If we make sure that the MPS is properly normalized and subtract the current energy density from every term in the hamiltonian, $h \\leftarrow h - e$, the gradient takes on the simple form\n",
    "\n",
    "$$ g = 2 \\times \\partial_{\\bar{A}} \\left \\langle \\Psi(\\bar{A}) \\middle | h  \\middle | \\Psi(A) \\right \\rangle.$$\n",
    "\n",
    "Thus, the gradient is obtained by differentiating the expression\n",
    "\n",
    "<center><img src=\"img/grad.svg\" alt=\"gradient\"></center>\n",
    "\n",
    "with respect to $\\bar{A}$. This gives rise to a sum over all sites, where in every term we differentiate with respect to one tensor $\\bar{A}$ in the bra layer. Differentiating with respect to one $\\bar{A}$ tensor amounts to leaving out that tensor, and interpreting the open legs as outgoing ones, i.e. each term looks like\n",
    "\n",
    "<center><img src=\"img/gradTerm.svg\" alt=\"gradient term\"></center>\n",
    "\n",
    "The full gradient is then obtained as an infinite sum over these terms. By dividing the terms into three different classes and doing some bookkeeping as illustrated below, we can eventually write this sum in a relatively simple closed form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terms of the 'center' kind\n",
    "The first kind of terms that arise in the above expression for the gradient are obtained by differentiation with respect to an $\\bar{A}$ tensor on the legs of the Hamiltonian operator. This results in two 'center' terms\n",
    "\n",
    "<center><img src=\"img/centerTerms.svg\" alt=\"center terms\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradCenterTerms(hTilde, A, l=None, r=None):\n",
    "    \"\"\"\n",
    "    Calculate the value of the center terms.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight.\n",
    "        A : np.array (D, d, D)\n",
    "            normalized MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right.\n",
    "        l : np.array (D, D), optional\n",
    "            left fixed point of transfermatrix,\n",
    "            normalized.\n",
    "        r : np.array (D, D), optional\n",
    "            right fixed point of transfermatrix,\n",
    "            normalized.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        term1 : np.array (D, d, D)\n",
    "            first term of gradient,\n",
    "            ordered left-mid-right.\n",
    "        term2 : np.array (D, d, D)\n",
    "            second term of gradient,\n",
    "            ordered left-mid-right.\n",
    "    \"\"\"\n",
    "    \n",
    "    return term1, term2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terms of the 'left' kind\n",
    "For the terms where we leave out an $\\bar{A}$ tensor to the left of $h$, which we will call 'left' terms, we can contract everything to the left of this missing $\\bar{A}$ with the left fixed point $l$, while everything to the right of $h$ can be contracted with right fixed point $r$.\n",
    "\n",
    "In between these two outer parts of the network there remains a region where the regular MPS transfer matrix $E$ is applied a number of times. The action of this region is therefore captured by the operator $E^n$, where the power $n$ is determined by the seperation between the outer left and right parts for the specific term under consideration. When summing all left terms, the outer parts of the contraction always remain the same, while only the power $n$ differs for every term. Thus, summing all left terms corresponds to contracting the operator \n",
    "\n",
    "$$E_\\text{sum} = 1 + E + E^2 + \\dots = \\frac{1}{1-E}$$\n",
    "\n",
    "between the left and right outer parts. Here, we have naively used the geometric series to write the sum in a closed form. However, since by our normalization the transfer matrix has leading eigenvalue $1$, this resulting expression will diverge and is therefore ill-defined. We can get around this by introducing a regularized transfer matrix $\\tilde{E}$ which is defined by subtracting the divergent part,\n",
    "\n",
    "<center><img src=\"img/regTransfer.svg\" alt=\"regularized transfer matrix\"></center>\n",
    "\n",
    "Since we have already shifted the energy density to have a zero expectation value, $h \\leftarrow h - e$, it can easily be verified that the contribution of the leading divergent part vanishes in every left term, meaning that we can simply replace the original transfer matrix by its regularized version without changing any of the terms, and only then take the infinite sum which now has a well defined expression in terms of an inverse,\n",
    "\n",
    "$$ E_\\text{sum} \\rightarrow \\frac{1}{1-\\tilde{E}} \\equiv (1 - E)^P ,$$\n",
    "\n",
    "where we have introduced the pseudo-inverse defined as $(1 - E)^P = (1-\\tilde{E})^{-1}$.\n",
    "\n",
    "Using this notation we can define the partial contraction\n",
    "\n",
    "<center><img src=\"img/Rh.svg\" alt=\"right effective environment\"></center>\n",
    "\n",
    "such that the sum of all left terms equals\n",
    "\n",
    "<center><img src=\"img/leftTerms.svg\" alt=\"left terms\"></center>\n",
    "\n",
    "If we would compute the partial contraction $R_h$ directly by explicitly computing the pseudo-inverse, this would entail a computational complexity $O(D^6)$. Instead, we can define $L_h$ as the solution of a linear system by multiplying both sides of the corresponding definition by $(1-\\tilde{E})$. This results in an equation of the form $Ax = b$, which may be solved for $x$ by using Krylov-based iterative methods such as a Generalized Minimal RESidual (GMRES) algorithm. Note that these methods only require the action of $A = (1-\\tilde{E})$ on a vector and not the full matrix $A$. This action can again be supplied to the linear solver using a function handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducedHamUniform(h, A, l=None, r=None):\n",
    "    \"\"\"\n",
    "    Regularize Hamiltonian such that its expectation value is 0.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        h : np.array (d, d, d, d)\n",
    "            Hamiltonian that needs to be reduced,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight.\n",
    "        A : np.array (D, d, D)\n",
    "            normalized MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right.\n",
    "        l : np.array (D, D), optional\n",
    "            left fixed point of transfermatrix,\n",
    "            normalized.\n",
    "        r : np.array (D, D), optional\n",
    "            right fixed point of transfermatrix,\n",
    "            normalized.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight.\n",
    "    \"\"\"\n",
    "    \n",
    "    return hTilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EtildeRight(A, l, r, v):\n",
    "    \"\"\"\n",
    "    Implement the action of (1 - Etilde) on a right vector v.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        A : np.array (D, d, D)\n",
    "            normalized MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right.\n",
    "        l : np.array (D, D), optional\n",
    "            left fixed point of transfermatrix,\n",
    "            normalized.\n",
    "        r : np.array (D, D), optional\n",
    "            right fixed point of transfermatrix,\n",
    "            normalized.\n",
    "        v : np.array (D**2)\n",
    "            right matrix of size (D, D) on which\n",
    "            (1 - Etilde) acts,\n",
    "            given as a vector of size (D**2,)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        vNew : np.array (D**2)\n",
    "            result of action of (1 - Etilde)\n",
    "            on a right matrix,\n",
    "            given as a vector of size (D**2,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # given as an example\n",
    "    \n",
    "    D = A.shape[0]\n",
    "    \n",
    "    # reshape to matrix\n",
    "    v = v.reshape(D, D)\n",
    "        \n",
    "    # transfermatrix contribution\n",
    "    transfer = ncon((A, np.conj(A), v), ([-1, 2, 1], [-2, 2, 3], [1, 3]))\n",
    "\n",
    "    # fixed point contribution\n",
    "    fixed = np.trace(l @ v) * r\n",
    "\n",
    "    # sum these with the contribution of the identity\n",
    "    vNew = v - transfer + fixed\n",
    "\n",
    "    return vNew.reshape((D ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RhUniform(hTilde, A, l=None, r=None):\n",
    "    \"\"\"\n",
    "    Find the partial contraction for Rh.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight,\n",
    "            renormalized.\n",
    "        A : np.array (D, d, D)\n",
    "            normalized MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right.\n",
    "        l : np.array (D, D), optional\n",
    "            left fixed point of transfermatrix,\n",
    "            normalized.\n",
    "        r : np.array (D, D), optional\n",
    "            right fixed point of transfermatrix,\n",
    "            normalized.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Rh : np.array (D, D)\n",
    "            result of contraction,\n",
    "            ordered top-bottom.\n",
    "    \"\"\"\n",
    "    \n",
    "    # given as an example\n",
    "    \n",
    "    D = A.shape[0]\n",
    "    \n",
    "    # if l, r not specified, find fixed points\n",
    "    if l is None or r is None:\n",
    "        l, r = fixedPoints(A)\n",
    "    \n",
    "    # construct b, which is the matrix to the right of (1 - E)^P in the figure above\n",
    "    b = ncon((r, A, A, np.conj(A), np.conj(A), hTilde), ([4, 5], [-1, 2, 1], [1, 3, 4], [-2, 8, 7], [7, 6, 5], [2, 3, 8, 6]))\n",
    "    \n",
    "    # solve Ax = b for x\n",
    "    A = LinearOperator((D ** 2, D ** 2), matvec=partial(EtildeRight, A, l, r))\n",
    "    Rh = gmres(A, b.reshape(D ** 2))[0]\n",
    "    \n",
    "    return Rh.reshape((D, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradLeftTerms(hTilde, A, l=None, r=None):\n",
    "    \"\"\"\n",
    "    Calculate the value of the left terms.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight,\n",
    "            renormalized.\n",
    "        A : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right.\n",
    "        l : np.array (D, D), optional\n",
    "            left fixed point of transfermatrix,\n",
    "            normalized.\n",
    "        r : np.array (D, D), optional\n",
    "            right fixed point of transfermatrix,\n",
    "            normalized.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        leftTerms : np.array (D, d, D)\n",
    "            left terms of gradient,\n",
    "            ordered left-mid-right.\n",
    "    \"\"\"\n",
    "    \n",
    "    return leftTerms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terms of the 'right' kind\n",
    "\n",
    "In a similar way, the terms where we leave out an $\\bar{A}$ to the right of  $h$ can be evaluated by defining the partial contraction\n",
    "\n",
    "<center><img src=\"img/Lh.svg\" alt=\"Lh\"></center>\n",
    "\n",
    "which can again be found by solving a linear system, such that the sum of all right terms can be written as\n",
    "\n",
    "<center><img src=\"img/rightTerms.svg\" alt=\"rightTerms\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EtildeLeft(A, l, r, v):\n",
    "    \"\"\"\n",
    "    Implement the action of (1 - Etilde) on a left vector matrix v.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        A : np.array (D, d, D)\n",
    "            normalized MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right.\n",
    "        l : np.array (D, D), optional\n",
    "            left fixed point of transfermatrix,\n",
    "            normalized.\n",
    "        r : np.array (D, D), optional\n",
    "            right fixed point of transfermatrix,\n",
    "            normalized.\n",
    "        v : np.array (D**2)\n",
    "            right matrix of size (D, D) on which\n",
    "            (1 - Etilde) acts,\n",
    "            given as a vector of size (D**2,)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        vNew : np.array (D**2)\n",
    "            result of action of (1 - Etilde)\n",
    "            on a left matrix,\n",
    "            given as a vector of size (D**2,)\n",
    "    \"\"\"\n",
    "    \n",
    "    return vNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LhUniform(hTilde, A, l=None, r=None):\n",
    "    \"\"\"\n",
    "    Find the partial contraction for Lh.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight,\n",
    "            renormalized.\n",
    "        A : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right.\n",
    "        l : np.array (D, D), optional\n",
    "            left fixed point of transfermatrix,\n",
    "            normalized.\n",
    "        r : np.array (D, D), optional\n",
    "            right fixed point of transfermatrix,\n",
    "            normalized.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Lh : np.array (D, D)\n",
    "            result of contraction,\n",
    "            ordered bottom-top.\n",
    "    \"\"\"\n",
    "    \n",
    "    return Lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradRightTerms(hTilde, A, l=None, r=None):\n",
    "    \"\"\"\n",
    "    Calculate the value of the right terms.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight,\n",
    "            renormalized.\n",
    "        A : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right.\n",
    "        l : np.array (D, D), optional\n",
    "            left fixed point of transfermatrix,\n",
    "            normalized.\n",
    "        r : np.array (D, D), optional\n",
    "            right fixed point of transfermatrix,\n",
    "            normalized.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        rightTerms : np.array (D, d, D)\n",
    "            right terms of gradient,\n",
    "            ordered left-mid-right.\n",
    "    \"\"\"\n",
    "    \n",
    "    return rightTerms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The gradient\n",
    "\n",
    "The full gradient is then found by summing the contributions of all three types of terms,\n",
    "\n",
    "<center><img src=\"img/gradFull.svg\" alt=\"gradient\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(h, A, l=None, r=None):\n",
    "    \"\"\"\n",
    "    Calculate the gradient of the expectation value of h @ MPS A.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        h : np.array (d, d, d, d)\n",
    "            Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight,\n",
    "            renormalized.\n",
    "        A : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right.\n",
    "        l : np.array (D, D), optional\n",
    "            left fixed point of transfermatrix,\n",
    "            normalized.\n",
    "        r : np.array (D, D), optional\n",
    "            right fixed point of transfermatrix,\n",
    "            normalized.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        grad : np.array (D, d, D)\n",
    "            Gradient,\n",
    "            ordered left-mid-right.\n",
    "    \"\"\"\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Gradient descent algorithms\n",
    "\n",
    "The most straightforward way to use this expression for the gradient to find the ground state of a Hamiltonian is to implement a gradient-search method for minimizing the energy expecation value. The simplest such method is a steepest-descent search, where in every iteration the tensor $A$ is updated in the direction opposite to the gradient along a small step $\\varepsilon$,\n",
    "\n",
    "$$ A_{i+1} = A_i - \\varepsilon g .$$\n",
    "\n",
    "This procedure is repeated until we find the optimal MPS tensor $A^*$ for which the gradient vanishes. This approach can be improved upon by resorting to other optimization schemes such a conjugate-gradient or quasi-Newton methods. Below we demonstrate both a simple steepest-descent with a fixed step size, as well as an approach using routines supplied by the scipy package in `scipy.optimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groundStateGradDescent(h, D, eps=1e-1, A0=None, tol=1e-4, maxIter=1e4, verbose=True):\n",
    "    \"\"\"\n",
    "    Find the ground state using gradient descent.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        h : np.array (d, d, d, d)\n",
    "            Hamiltonian to minimize,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight.\n",
    "        D : int\n",
    "            Bond dimension\n",
    "        eps : float\n",
    "            Stepsize.\n",
    "        A0 : np.array (D, d, D)\n",
    "            normalized MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            initial guess.\n",
    "        tol : float\n",
    "            Tolerance for convergence criterium.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        E : float\n",
    "            expectation value @ minimum\n",
    "        A : np.array (D, d, D)\n",
    "            ground state MPS,\n",
    "            ordered left-mid-right.\n",
    "    \"\"\"\n",
    "    \n",
    "    d = h.shape[0]\n",
    "    \n",
    "    # if no initial value, choose random\n",
    "    if A0 is None:\n",
    "        A0 = createMPS(D, d)\n",
    "        A0 = normalizeMPS(A0)\n",
    "    \n",
    "    # calculate gradient\n",
    "    g = gradient(h, A0)\n",
    "    g0 = np.zeros((D, d, D))\n",
    "    \n",
    "    A = A0\n",
    "    \n",
    "    i = 0\n",
    "    while not(np.linalg.norm(g) < tol):\n",
    "        # do a step\n",
    "        A = A - eps * g\n",
    "        A = normalizeMPS(A)\n",
    "        i += 1\n",
    "        \n",
    "        if verbose and not(i % 100):\n",
    "            E = np.real(expVal2Uniform(h, A))\n",
    "            print('iteration:\\t{:d}\\tenergy:\\t{:.12f}\\tgradient norm:\\t{:.4e}'.format(i, E, np.linalg.norm(g)))\n",
    "        \n",
    "        # calculate new gradient\n",
    "        g = gradient(h, A)\n",
    "        \n",
    "        if i > maxIter:\n",
    "            print('Warning: gradient descent did not converge!')\n",
    "            break\n",
    "    \n",
    "    # calculate ground state energy\n",
    "    E = np.real(expVal2Uniform(h, A))\n",
    "    \n",
    "    return E, A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the minimize function from scipy for this purpose, one must keep in mind the fact that minimize requires an objective function that maps a real vector to a scalar. In particular, complex tensors must be given as reals vectors in the input, and must be again represented as real vectors in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groundStateMinimize(h, D, A0=None, tol=1e-4):\n",
    "    \"\"\"\n",
    "    Find the ground state using a scipy minimizer.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        h : np.array (d, d, d, d)\n",
    "            Hamiltonian to minimize,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight.\n",
    "        D : int\n",
    "            Bond dimension\n",
    "        A0 : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            initial guess.\n",
    "        tol : float\n",
    "            Relative convergence criterium.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        E : float\n",
    "            expectation value @ minimum\n",
    "        A : np.array (D, d, D)\n",
    "            ground state MPS,\n",
    "            ordered left-mid-right.\n",
    "    \"\"\"\n",
    "    \n",
    "    d = h.shape[0]\n",
    "    \n",
    "    def unwrapper(varA):\n",
    "        \"\"\"\n",
    "        Unwraps real MPS vector to complex MPS tensor.\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            varA : np.array (2 * D * d * D)\n",
    "                MPS tensor in real vector form.\n",
    "            D : int\n",
    "                Bond dimension.\n",
    "            d : int\n",
    "                Physical dimension.\n",
    "                \n",
    "            Returns\n",
    "            -------\n",
    "            A : np.array (D, d, D)\n",
    "                MPS tensor with 3 legs,\n",
    "                ordered left-bottom-right.\n",
    "        \"\"\"\n",
    "        \n",
    "        # unpack real and imaginary part\n",
    "        Areal = varA[:D ** 2 * d]\n",
    "        Aimag = varA[D ** 2 * d:]\n",
    "        \n",
    "        A = Areal + 1.0j * Aimag\n",
    "        \n",
    "        return np.reshape(A, (D, d, D))\n",
    "    \n",
    "    def wrapper(A):\n",
    "        \"\"\"\n",
    "        Wraps MPS tensor to real MPS vector.\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            A : np.array (D, d, D)\n",
    "                MPS tensor,\n",
    "                ordered left-bottom-right\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            varA : np.array (2 * D * d * D)\n",
    "                MPS tensor in real vector form.\n",
    "        \"\"\"\n",
    "        \n",
    "        # split into real and imaginary part\n",
    "        Areal = np.real(A)\n",
    "        Aimag = np.imag(A)\n",
    "        \n",
    "        # combine into vector\n",
    "        varA = np.concatenate( (Areal.reshape(-1), Aimag.reshape(-1)) )\n",
    "        \n",
    "        return varA\n",
    "    \n",
    "    # if no initial MPS, take random one\n",
    "    if A0 is None:\n",
    "        A0 = createMPS(D, d)\n",
    "        A0 = normalizeMPS(A0)\n",
    "    \n",
    "    # define f for minimize in scipy\n",
    "    def f(varA):\n",
    "        \"\"\"\n",
    "        Function to optimize via minimize.\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            varA : np.array (2 * D * d * D)\n",
    "                MPS tensor in real vector form.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            e : float\n",
    "                function value @varA\n",
    "            g : np.array (2 * D * d * D)\n",
    "                gradient vector @varA\n",
    "        \"\"\"\n",
    "        \n",
    "        # unwrap varA\n",
    "        A = unwrapper(varA)\n",
    "        A = normalizeMPS(A)\n",
    "        \n",
    "        # calculate fixed points\n",
    "        l, r = fixedPoints(A)\n",
    "        \n",
    "        # calculate function value and gradient\n",
    "        e = np.real(expVal2Uniform(h, A, l, r))\n",
    "        g = gradient(h, A, l, r)\n",
    "        \n",
    "        # wrap g\n",
    "        g = wrapper(g)\n",
    "        \n",
    "        return e, g\n",
    "    \n",
    "    # calculate minimum\n",
    "    result = minimize(f, wrapper(A0), jac=True, tol=tol)\n",
    "    \n",
    "    # unpack result\n",
    "    E = result.fun\n",
    "    A = unwrapper(result.x)\n",
    "    \n",
    "    return E, A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate these methods, we now have a look the specific case of the antiferromagnetic spin-1 Heisenberg model in one dimension. To this end we first define the spin-1 Heisenberg Hamiltonian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Heisenberg(Jx, Jy, Jz, hz):\n",
    "    \"\"\"\n",
    "    Construct the spin-1 Heisenberg Hamiltonian for given couplings.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        Jx : float\n",
    "            Coupling strength in x direction\n",
    "        Jy : float\n",
    "            Coupling strength in y direction\n",
    "        Jy : float\n",
    "            Coupling strength in z direction\n",
    "        hz : float\n",
    "            Coupling for Sz terms\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        h : np.array (3, 3, 3, 3)\n",
    "            Spin-1 Heisenberg Hamiltonian.\n",
    "    \"\"\"\n",
    "    Sx = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]]) / np.sqrt(2)\n",
    "    Sy = np.array([[0, -1, 0], [1, 0, -1], [0, 1, 0]]) * 1.0j /np.sqrt(2)\n",
    "    Sz = np.array([[1, 0, 0], [0, 0, 0], [0, 0, -1]])\n",
    "    I = np.eye(3)\n",
    "\n",
    "    return -Jx*ncon((Sx, Sx), ([-1, -3], [-2, -4]))-Jy*ncon((Sy, Sy), ([-1, -3], [-2, -4]))-Jz*ncon((Sz, Sz), ([-1, -3], [-2, -4])) \\\n",
    "            - hz*ncon((I, Sz), ([-1, -3], [-2, -4])) - hz*ncon((Sz, I), ([-1, -3], [-2, -4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, D = 3, 12\n",
    "A = createMPS(D, d)\n",
    "A = normalizeMPS(A)\n",
    "\n",
    "h = Heisenberg(-1, -1, -1, 0)\n",
    "\n",
    "# energy optimization using naive gradient descent\n",
    "# for D=12 or higher: tolerance lower than 1e-2 gives very long runtimes\n",
    "print('Gradient descent optimization:\\n')\n",
    "t0 = time()\n",
    "E1, A1 = groundStateGradDescent(h, D, eps=1e-1, A0=A, tol=1e-2, maxIter=1e4)\n",
    "print('Time until convergence:', time()-t0, 's')\n",
    "print('Computed energy:', E1, '\\n')\n",
    "\n",
    "# energy optimization using scipy optimizer\n",
    "# for D=12 and tolerance 1e-5: runtime of somewhere around 100s\n",
    "print('Optimization using scipy minimize:\\n')\n",
    "t0 = time()\n",
    "E2, A2 = groundStateMinimize(h, D, A0=A, tol=1e-4)\n",
    "print('Time until convergence:', time()-t0, 's')\n",
    "print('Computed energy:', E2, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 The VUMPS algorithm\n",
    "\n",
    "In the previous section we have derived an expression for the gradient starting from an MPS in the uniform gauge, which corresponds to an object that lives in the space of MPS tensors. We now discuss how to improve upon direct optimization schemes based on this form of the gradient by exploiting the structure of the MPS manifold as well as the mixed gauge for MPS.\n",
    "\n",
    "Indeed, while the gradient in the above form indicates a direction in the space of complex tensors in which the energy decreases, intuitively it would make more sense if we could find a way to interpret the gradient as a direction *along the MPS manifold* along which we can decrease the energy. This can be achieved by interpreting the gradient as a *tangent vector in the tangent space to the MPS manifold*. By formulating the energy optimization in terms of this tangent space gradient written in mixed gauge, one arives at the [VUMPS](https://doi.org/10.1103/PhysRevB.97.045145) algorithm (which stand for 'variational uniform matrix product states'). The precise derivation of the tangent space gradient in mixed gauge falls beyond the scope of this tutorial, and can be found in the [lecture notes](https://doi.org/10.21468/SciPostPhysLectNotes.7). Instead we will simply illustrate the implementation of the VUMPS algorithm given the mixed gauge tangent space gradient.\n",
    "\n",
    "Most of the following required steps will be reminiscent of those outlined above, where we now consistently work in the mixed gauge. We start off by implementing the regularization of the two-site Hamiltonian in the mixed gauge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducedHamMixed(h, Ac, Ar):\n",
    "    \"\"\"\n",
    "    Regularize Hamiltonian such that its expectation value is 0.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        h : np.array (d, d, d, d)\n",
    "            Hamiltonian that needs to be reduced,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight.\n",
    "        Ac : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            center gauged.\n",
    "        Ar : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            right gauged.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight.\n",
    "    \"\"\"\n",
    "    \n",
    "    return hTilde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variational optimum of the energy is characterized by the condition that the gradient is zero at this point. Writing the tangent space gradient as $G$, we now wish to formulate an algorithm which minimizes the error measure\n",
    "\n",
    "$$ \\varepsilon = \\left( \\boldsymbol{G}^\\dagger \\boldsymbol{G} \\right)^{1/2} $$\n",
    "\n",
    "in an efficient way. The explicit form of the tangent space gradient in mixed gauge is given by\n",
    "\n",
    "$$ G = A^\\prime_{C} - A_L C^\\prime = A^\\prime_{C} - C^\\prime A_R, $$\n",
    "\n",
    "where $A^\\prime_{C}$ and $C^\\prime$ are defined as\n",
    "\n",
    "<center><img src=\"img/Acprime.svg\" alt=\"Ac prime\"></center>\n",
    "\n",
    "and\n",
    "\n",
    "<center><img src=\"img/Cprime.svg\" alt=\"C prime\"></center>\n",
    "\n",
    "Here, we again use $L_h$ and $R_h$ to indicate the partial contractions\n",
    "\n",
    "<center><img src=\"img/LhMixed.svg\" alt=\"Lh mixed gauge\"></center>\n",
    "\n",
    "and\n",
    "\n",
    "<center><img src=\"img/RhMixed.svg\" alt=\"Rh mixed gauge\"></center>\n",
    "\n",
    "where the transfer matrices $E^L_L$ and $E^R_R$ appearing in these expressions now contain only left-gauged and right-gauged MPS tensors $A_L$ and $A_R$ respectively.\n",
    "\n",
    "If we interpret the two terms appearing in the tangent space gradient as defining the effective Hamiltonians $H_{A_C}(\\cdot)$ and $H_C(\\cdot)$ such that\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "H_{A_C}(A_C) = A_C^\\prime \\\\\n",
    "H_C(C) = C^\\prime ,\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "we can characterize the variational optimum in terms of the fixed points of these operators. Indeed, since the tangent space gradient should be zero at the variational optimum, this point satisfies $A_C' = A_L C' = C' A_R$. This implies that the optimal MPS should obey the following set of equations,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "H_{A_C}(A_C) \\propto A_C \\\\\n",
    "H_C(C) \\propto C \\\\\n",
    "A_C = A_L C = C A_R ,\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "meaning that the optimal MPS should correspond to a fixed point of the effective Hamiltonians $H_{A_C}$ and $H_C$ and satisfy the mixed gauge condition. The VUMPS algorithm then consists of an iterative method for finding a set $\\{A_L, A_C, A_R, C\\}$ that satisfies these equations simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the required operators\n",
    "\n",
    "Similar to before, we again have to compute the contributions of the left and right environment terms $L_h$ and $R_h$ given above. We therefore require function handles defining the action of the left (resp. right) transfer matrix $E^L_L$ (resp. $E^R_R$) on a left (resp. right) matrix. To this end, we can simply reuse the implementations `EtildeLeft` and `EtildeRight` defined above, if we take into account that the left (resp. right) fixed point of $E^L_L$ (resp. $E^R_R$) is the identity while its right (resp. left) fixed point is precisely $C C^\\dagger$ (resp. $C^\\dagger C$). This last fact follows immediately from the mixed gauge condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LhMixed(hTilde, Al, C, tol=1e-5):\n",
    "    \"\"\"\n",
    "    Calculate Lh, for a given MPS in mixed gauge.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight,\n",
    "            renormalized.\n",
    "        Al : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            left-orthonormal.\n",
    "        C : np.array (D, D)\n",
    "            Center gauge with 2 legs,\n",
    "            ordered left-right.\n",
    "        tol : float, optional\n",
    "            tolerance for gmres\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Lh : np.array (D, D)\n",
    "            result of contraction,\n",
    "            ordered bottom-top.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return Lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RhMixed(hTilde, Ar, C, tol=1e-5):\n",
    "    \"\"\"\n",
    "    Calculate Rh, for a given MPS in mixed gauge.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight,\n",
    "            renormalized.\n",
    "        Ar : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            right-orthonormal.\n",
    "        C : np.array (D, D)\n",
    "            Center gauge with 2 legs,\n",
    "            ordered left-right.\n",
    "        tol : float, optional\n",
    "            tolerance for gmres\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Rh : np.array (D, D)\n",
    "            result of contraction,\n",
    "            ordered top-bottom.\n",
    "    \"\"\"\n",
    "    \n",
    "    return Rh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we implement the actions of the effective Hamiltonians $H_{A_C}$ and $H_{C}$ defined above,\n",
    "\n",
    "<center><img src=\"img/H_Ac.svg\" alt=\"H_Ac\"></center>\n",
    "\n",
    "<center><img src=\"img/H_C.svg\" alt=\"H_C\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_Ac(hTilde, Al, Ar, Lh, Rh, v):\n",
    "    \"\"\"\n",
    "    Action of the effective Hamiltonian for Ac (131) on a vector.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight,\n",
    "            renormalized.\n",
    "        Al : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            left-orthonormal.\n",
    "        Ar : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            right-orthonormal.\n",
    "        Lh : np.array (D, D)\n",
    "            left environment,\n",
    "            ordered bottom-top.\n",
    "        Rh : np.array (D, D)\n",
    "            right environment,\n",
    "            ordered top-bottom.\n",
    "        v : np.array (D, d, D)\n",
    "            Tensor of size (D, d, D)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        H_AcV : np.array (D, d, D)\n",
    "            Result of the action of H_Ac on the vector v,\n",
    "            representing a tensor of size (D, d, D)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # given as an example\n",
    "    \n",
    "    # first term\n",
    "    term1 = ncon((Al, v, np.conj(Al), hTilde), ([4, 2, 1], [1, 3, -3], [4, 5, -1], [2, 3, 5, -2]))\n",
    "\n",
    "    # second term\n",
    "    term2 = ncon((v, Ar, np.conj(Ar), hTilde), ([-1, 2, 1], [1, 3, 4], [-3, 5, 4], [2, 3, -2, 5]))\n",
    "\n",
    "    # third term\n",
    "    term3 = ncon((Lh, v), ([-1, 1], [1, -2, -3]))\n",
    "\n",
    "    # fourth term\n",
    "    term4 = ncon((v, Rh), ([-1, -2, 1], [1, -3]))\n",
    "\n",
    "    # sum\n",
    "    H_AcV = term1 + term2 + term3 + term4\n",
    "\n",
    "    return H_AcV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_C(hTilde, Al, Ar, Lh, Rh, v):\n",
    "    \"\"\"\n",
    "    Action of the effective Hamiltonian for Ac (131) on a vector.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight,\n",
    "            renormalized.\n",
    "        Al : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            left-orthonormal.\n",
    "        Ar : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            right-orthonormal.\n",
    "        Lh : np.array (D, D)\n",
    "            left environment,\n",
    "            ordered bottom-top.\n",
    "        Rh : np.array (D, D)\n",
    "            right environment,\n",
    "            ordered top-bottom.\n",
    "        v : np.array (D, D)\n",
    "            Matrix of size (D, D)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        H_CV : np.array (D, D)\n",
    "            Result of the action of H_C on the matrix v.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return H_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing the VUMPS algorithm\n",
    "\n",
    "In order to find a set $\\{A_L^*, A_C^*, A_R^*, C^*\\}$ that satisfies the VUMPS fixed point equations given above, we use an iterative method in which each iteration consists of the following steps, each time starting from a given set $\\{A_L, A_C, A_R, C\\}$:\n",
    "\n",
    "1. Solve the eigenvalue equations for $H_{A_C}$ and $H_C$, giving new center tensors $\\tilde{A}_C$ and $\\tilde{C}$.\n",
    "\n",
    "2. From these new center tensors, construct a set $\\{\\tilde{A}_L, \\tilde{A}_R, \\tilde{A}_C, \\tilde{C}\\}$.\n",
    "\n",
    "3. Update the set of tensors $\\{A_L, A_C, A_R, C\\} \\leftarrow \\{\\tilde{A}_L, \\tilde{A}_C, \\tilde{A}_R, \\tilde{C}\\}$ and evaluate the norm of the gradient $\\varepsilon = \\left | \\left | H_{A_C} (A_C) - A_L H_C(C) \\right | \\right |$.\n",
    "\n",
    "4. If the norm of the gradient lies above the given tolerance, repeat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Updating the center tensors\n",
    "\n",
    "We start by defining a routine `calcNewCenter` which finds the new center tensors $\\tilde{A}_C$ and $\\tilde{C}$ by solving the eigenvalue problem defined by the effective Hamiltonians implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcNewCenter(hTilde, Al, Ac, Ar, C, Lh=None, Rh=None, tol=1e-5):\n",
    "    \"\"\"\n",
    "    Find new guess for Ac and C as fixed points of the maps H_Ac and H_C.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight,\n",
    "            renormalized.\n",
    "        Al : np.array (D, d, D)\n",
    "            MPS tensor zith 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            left orthonormal.\n",
    "        Ar : np.array (D, d, D)\n",
    "            MPS tensor zith 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            right orthonormal.\n",
    "        Ac : np.array (D, d, D)\n",
    "            MPS tensor zith 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            center gauge.\n",
    "        C : np.array (D, D)\n",
    "            Center gauge with 2 legs,\n",
    "            ordered left-right.\n",
    "        Lh : np.array (D, D)\n",
    "            left environment,\n",
    "            ordered bottom-top.\n",
    "        Rh : np.array (D, D)\n",
    "            right environment,\n",
    "            ordered top-bottom.\n",
    "        tol : float, optional\n",
    "            current tolerance\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        AcTilde : np.array (D, d, D)\n",
    "            MPS tensor zith 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            center gauge.\n",
    "        CTilde : np.array (D, D)\n",
    "            Center gauge with 2 legs,\n",
    "            ordered left-right.\n",
    "    \"\"\"\n",
    "    \n",
    "    return AcTilde, CTilde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract a new set of mixed-gauge MPS tensors\n",
    "\n",
    "Once we have new center tensors, we can use these to construct a new set of mixed-gauge MPS tensors. To do this in a stable way, we will determine the global updates $\\tilde{A}_L$ and $\\tilde{A}_R$ as the left and right isometric tensors that minimize\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\varepsilon_L = \\min ||\\tilde{A}_C - \\tilde{A}_L \\tilde{C}||_2 \\\\\n",
    "\\varepsilon_R = \\min ||\\tilde{A}_C - \\tilde{C} \\tilde{A}_L||_2 .\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This can be achieved in a robust and close to optimal way by making use of the left and right polar decompositions\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\tilde{A}_C = U^l_{A_C} P^l_{A_C}, \\qquad \\tilde{C} = U^l_{C} P^l_{C}, \\\\\n",
    "\\tilde{A}_C = P^r_{A_C}  U^r_{A_C} , \\qquad \\tilde{C} = P^r_{C} U^r_{C},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "to obtain\n",
    "\n",
    "$$ \\tilde{A}_L = U^l_{A_C} (U^l_C)^\\dagger, \\qquad \\tilde{A}_R = (U^r_C)^\\dagger U^r_{A_C}. $$\n",
    "\n",
    "In order to give the  procedure some additional stability, we may also choose to use the $\\tilde{A}_L$ obtained with these polar decompositions to compute the tensors $\\tilde{A}_R$ and $\\tilde{A}_C$ by right orthonormalization of this $\\tilde{A}_L$. This approach ensures that the MPS satisfies the mixed gauge condition at all times, improving the overal stabilitiy of the VUMPS algorithm. This procedure is implemented in the `minAcC` routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minAcC(AcTilde, CTilde, tol=1e-5):\n",
    "    \"\"\"\n",
    "    Find Al and Ar corresponding to Ac and C, according to algorithm 5 in the lecture notes.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        AcTilde : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            new guess for center gauge. \n",
    "        CTilde : np.array (D, D)\n",
    "            Center gauge with 2 legs,\n",
    "            ordered left-right,\n",
    "            new guess for center gauge\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Al : np.array (D, d, D)\n",
    "            MPS tensor zith 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            left orthonormal.\n",
    "        Ar : np.array (D, d, D)\n",
    "            MPS tensor zith 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            right orthonormal.\n",
    "        Ac : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            center gauge. \n",
    "        C : np.array (D, D)\n",
    "            Center gauge with 2 legs,\n",
    "            ordered left-right,\n",
    "            center gauge\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return Al, Ac, Ar, C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating the norm of the gradient\n",
    "\n",
    "As a last step, we use the routine `gradientNorm` to compute the norm of the tangent space gradient in order to check if the procedure has converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientNorm(hTilde, Al, Ac, Ar, C, Lh, Rh):\n",
    "    \"\"\"\n",
    "    Calculate the norm of the gradient.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        hTilde : np.array (d, d, d, d)\n",
    "            reduced Hamiltonian,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight,\n",
    "            renormalized.\n",
    "        Al : np.array (D, d, D)\n",
    "            MPS tensor zith 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            left orthonormal.\n",
    "        Ar : np.array (D, d, D)\n",
    "            MPS tensor zith 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            right orthonormal.\n",
    "        Ac : np.array (D, d, D)\n",
    "            MPS tensor zith 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            center gauge.\n",
    "        C : np.array (D, D)\n",
    "            Center gauge with 2 legs,\n",
    "            ordered left-right.\n",
    "        Lh : np.array (D, D)\n",
    "            left environment,\n",
    "            ordered bottom-top.\n",
    "        Rh : np.array (D, D)\n",
    "            right environment,\n",
    "            ordered top-bottom.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        norm : float\n",
    "            norm of the gradient @Al, Ac, Ar, C\n",
    "    \"\"\"\n",
    "    \n",
    "    # given\n",
    "    \n",
    "    D = Al.shape[0]\n",
    "    d = Al.shape[1]\n",
    "    \n",
    "    # calculate update on Ac and C using maps H_Ac and H_c\n",
    "    AcUpdate = H_Ac(hTilde, Al, Ar, Lh, Rh, Ac)\n",
    "    CUpdate = H_C(hTilde, Al, Ar, Lh, Rh, C)\n",
    "    AlCupdate = ncon((Al, CUpdate), ([-1, -2, 1], [1, -3]))\n",
    "    \n",
    "    norm = np.linalg.norm(AcUpdate - AlCupdate)\n",
    "    \n",
    "    return norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this allows to implement the VUMPS algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vumps(h, D, A0=None, tol=1e-4, tolFactor=1e-1, verbose=True):\n",
    "    \"\"\"\n",
    "    Find the ground state of a given Hamiltonian using VUMPS.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        h : np.array (d, d, d, d)\n",
    "            Hamiltonian to minimize,\n",
    "            ordered topLeft-topRight-bottomLeft-bottomRight.\n",
    "        D : int\n",
    "            Bond dimension\n",
    "        A0 : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            initial guess.\n",
    "        tol : float\n",
    "            Relative convergence criterium.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        E : float\n",
    "            expectation value @ minimum\n",
    "        Al : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            left orthonormal.\n",
    "        Ar : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            right orthonormal.\n",
    "        Ac : np.array (D, d, D)\n",
    "            MPS tensor with 3 legs,\n",
    "            ordered left-bottom-right,\n",
    "            center gauge.\n",
    "        C : np.array (D, D)\n",
    "            Center gauge with 2 legs,\n",
    "            ordered left-right.\n",
    "    \"\"\"\n",
    "    \n",
    "    return E, Al, Ac, Ar, C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again test this implementation on the spin-1 Heisenberg antiferromagnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, D = 3, 12\n",
    "A = createMPS(D, d)\n",
    "A = normalizeMPS(A)\n",
    "\n",
    "h = Heisenberg(-1, -1, -1, 0)\n",
    "\n",
    "# energy optimization using VUMPS\n",
    "print('Energy optimization using VUMPS:\\n')\n",
    "t0 = time()\n",
    "E, Al, Ac, Ar, C = vumps(h, D, A0=A, tol=1e-4, tolFactor=1e-2, verbose=True)\n",
    "print('\\nTime until convergence:', time()-t0, 's\\n')\n",
    "print('Computed energy:', E, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having obtained this ground state MPS, it is worthwile to have a look at the corresponding entanglement spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, S, _ = svd(C) # singular values of center matrix give entanglement spectrum\n",
    "plt.figure(dpi=120)\n",
    "plt.title('Entanglement spectrum of ground state')\n",
    "plt.scatter(np.arange(D)+1, S, marker='x')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that the entanglement spectrum consists of degenerate groups, which reflects an underlying symmetry in the ground state of the spin-1 Heisenberg antiferromagnet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Elementary excitations\n",
    "\n",
    "#### Quasiparticle ansatz\n",
    "\n",
    "The methods described above can be extended beyond computing the ground state. We briefly discuss how one can also study excitations on top of a given ground state. For this, we introduce the MPS quasiparticle ansatz, given by\n",
    "\n",
    "<center><img src=\"img/excitation.svg\" alt=\"quasiparticle ansatz\"></center>\n",
    "\n",
    "This ansatz cosists of defining a new state by changing one $A$ tensor of the ground state at site $n$ and taking a momentum superposition.\n",
    "\n",
    "Before describing how to optimize the tensor $B$, it is worthwile to investigate the corresponding variational space in a bit more detail. First, we note that this excitation ansatz can be interpreted as nothing more than a boosted version of a tangent vector to the MPS manifold. In particular, this means that we will be able to apply all kinds of useful tricks and manipulations to the tensor $B$ (cfr. the [lecture notes](https://doi.org/10.21468/SciPostPhysLectNotes.7) for an introduction to tangent vectors and their properties). For example, we can see that $B$ has gauge degrees of freedom, as the corresponding excited state is invariant under an additive gauge transformation of the form\n",
    "\n",
    "<center><img src=\"img/gaugeExcitation.svg\" alt=\"gauge transform excitation\"></center>\n",
    "\n",
    "where $Y$ is an arbitrary $D \\times D$ matrix. This gauge freedom can be eliminated, thereby removing the zero modes in the variational subspace, by imposing a *left gauge-fixing condition*\n",
    "\n",
    "<center><img src=\"img/gaugeFix.svg\" alt=\"gauge fix\"></center>\n",
    "\n",
    "If we parametrize the tensor $B$ as\n",
    "\n",
    "<center><img src=\"img/VlX.svg\" alt=\"VlX\"></center>\n",
    "\n",
    "where $V_L$ is the $ D \\times d \\times D(d-1)$ tensor corresponding to the $D(d-1)$-dimensional null space of $A_L$ satisfying\n",
    "\n",
    "<center><img src=\"img/Vl.svg\" alt=\"Vl\"></center>\n",
    "\n",
    "then the gauge condition is automatically satisfied. In particular, this fixing of the gauge freedom ensures that the excitation is orthogonal to the ground state,\n",
    "\n",
    "<center><img src=\"img/excitationOrth.svg\" alt=\"excitationOrth\"></center>\n",
    "\n",
    "In this form, we have put forward an ansatz for an excited state characterized by a single $D(d-1) \\times D$ matrix $X$ such that\n",
    "\n",
    "1. All gauge degrees of freedom are fixed.\n",
    "2. All zero modes in the variational subspace are removed.\n",
    "3. Calculating the norm becomes straightforward.\n",
    "4. The excitation is orthogonal to the ground state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Solving the eigenvalue problem\n",
    "\n",
    "Having introduced an excitation  ansatz which has all the right properties and is defined in terms of a single matrix $X$, all that is left to do is to minimize the energy function,\n",
    "\n",
    "$$  \\min_{X} \\frac{\\left \\langle \\Phi_p(X) \\middle | H  \\middle | \\Phi_p(X) \\right \\rangle}{\\left \\langle \\Phi_p(X) \\middle | \\Phi_p(X)  \\right \\rangle}. $$\n",
    "\n",
    "As both the numerator and the denominator are quadratic functions of the variational parameters $X$, this optimization problem reduces to solving a generalized eigenvalue problem\n",
    "\n",
    "$$ H_{\\text{eff}}(q) X = \\omega N_{\\text{eff}}(q) X, $$\n",
    "\n",
    "where the effective energy and normalization matrices are defined as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "& 2\\pi\\delta(p-p') (\\boldsymbol{X'})^\\dagger H_{\\text{eff}}(q) \\boldsymbol{X} = \\left \\langle \\Phi_{p'}(X') \\middle | H  \\middle | \\Phi_p(X) \\right \\rangle \\\\\n",
    "& 2\\pi\\delta(p-p') (\\boldsymbol{X'})^\\dagger N_{\\text{eff}}(q) \\boldsymbol{X} = \\left \\langle \\Phi_{p'}(X') \\middle | \\Phi_p(X) \\right \\rangle,\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "and $\\boldsymbol{X}$ denotes a vectorized version of the matrix $X$. Since the overlap between two excited states is of the simple Euclidean form (cfr. the [lecture notes](https://doi.org/10.21468/SciPostPhysLectNotes.7)), the effective normalization matrix reduces to the unit matrix, and we are left with an ordinary eigenvalue problem.\n",
    "\n",
    "To solve this eigenvalue problem, we need to find an expression for $H_{\\text{eff}}$, or rather of the action thereof on a trial vector $\\boldsymbol{Y}$. In order to find this action we first transform the vector $\\boldsymbol{X}$ into a tensor $B$ by contracting its corresponding matrix with the right leg of $V_L$, and then compute all different contributions that pop up in a matrix element of the form $\\left \\langle \\Phi_p(B') \\middle | H  \\middle | \\Phi_p(B) \\right \\rangle$. This procedure is similar to what we have done when computing the gradient above, where we now need to take into account all different positions of the nearest-neighbor operator $h$ of the Hamiltonian, the input tensor $B$ and the output. Though slightly more involved than before, we can again define the following partion contractions\n",
    "\n",
    "<center><img src=\"img/LhMixed.svg\" alt=\"LhMixed\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src=\"img/RhMixed.svg\" alt=\"RhMixed\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src=\"img/LB.svg\" alt=\"LB\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src=\"img/RB.svg\" alt=\"RB\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src=\"img/L1.svg\" alt=\"L1\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src=\"img/R1.svg\" alt=\"R1\"></center>\n",
    "\n",
    "Using these partial contractions, we find the action of the effective energy matrix on a given input tensor $B(Y)$ as\n",
    "\n",
    "<center><img src=\"img/HeffExcitation.svg\" alt=\"HeffExcitation\"></center>\n",
    "\n",
    "In the last step, we need the action of $H_{\\text{eff}}(p)$ on the vector $\\boldsymbol{Y}$, so we need to perform a last contraction\n",
    "\n",
    "<center><img src=\"img/quasi_inveff.svg\" alt=\"quasi_inveff\"></center>\n",
    "\n",
    "The total procedure is implemented in the routine `quasiParticle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quasiParticle(h, Al, Ar, Ac, C, p, num):\n",
    "\n",
    "    tol, D, d = 1e-12, Al.shape[0], Al.shape[1]\n",
    "    # renormalize hamiltonian and find left and right environments\n",
    "    hTilde = reducedHamMixed(h, Ac, Ar)\n",
    "    Lh = LhMixed(hTilde, Al, C, tol)\n",
    "    Rh = RhMixed(hTilde, Ar, C, tol)\n",
    "    \n",
    "    def ApplyHeff(x):\n",
    "        \n",
    "        x = np.reshape(x, (D*(d-1), D))\n",
    "        B = ncon((Vl, x), ([-1, -2, 1], [1, -3]))\n",
    "        \n",
    "        def ApplyELR(x, p):\n",
    "            x = x.reshape((D,D))\n",
    "            overlap = ncon((np.conj(C), x),([1, 2], [1, 2]))\n",
    "            y = ncon((Al, np.conj(Ar), x), ([-1, 3, 1], [-2, 3, 2], [1, 2]))\n",
    "            y = x - np.exp(1j*p) * (y - overlap * C)\n",
    "            y = y.reshape(-1)\n",
    "            return y\n",
    "\n",
    "        def ApplyERL(x, p):\n",
    "            x = x.reshape((D,D))\n",
    "            overlap=ncon((np.conj(C), x), ([1, 2], [1, 2]))\n",
    "            y = ncon((x, Ar, np.conj(Al)), ([1, 2], [2, 3, -2], [1, 3, -1]))\n",
    "            y = x - np.exp(1j*p) * (y - overlap * C)\n",
    "            y = y.reshape(-1)\n",
    "            return y\n",
    "\n",
    "        \n",
    "        # right disconnected\n",
    "        right = ncon((B, np.conj(Ar)), ([-1, 2, 1], [-2, 2, 1]))\n",
    "        handleApplyELR = LinearOperator((D**2, D**2), matvec=lambda v: ApplyELR(v,p))\n",
    "        right = gmres(handleApplyELR, right.reshape(-1), tol=tol)[0]\n",
    "        right = right.reshape((D,D))\n",
    "        \n",
    "        # left disconnected\n",
    "        left = \\\n",
    "            1*ncon((Lh, B, np.conj(Al)), ([1,2], [2,3,-2],[1,3,-1]))+\\\n",
    "            1*ncon((Al, B, np.conj(Al), np.conj(Al), hTilde), ([1,2,4],[4,5,-2],[1,3,6],[6,7,-1],[3,7,2,5]))+\\\n",
    "            np.exp(-1j*p)*ncon((B, Ar, np.conj(Al), np.conj(Al), hTilde), ([1,2,4],[4,5,-2],[1,3,6],[6,7,-1],[3,7,2,5]))\n",
    "        handleApplyERL = LinearOperator((D**2, D**2), matvec=lambda v: ApplyERL(v, -p))\n",
    "        left = gmres(handleApplyERL, left.reshape(-1), tol=tol)[0]\n",
    "        left = left.reshape((D,D))\n",
    "        \n",
    "        y = \\\n",
    "            1*ncon((B,Ar,np.conj(Ar),hTilde),([-1,2,1],[1,3,4],[-3,5,4],[-2,5,2,3]))+\\\n",
    "            np.exp(1j*p)*ncon((Al,B,np.conj(Ar),hTilde),([-1,2,1],[1,3,4],[-3,5,4],[-2,5,2,3]))+\\\n",
    "            np.exp(-1j*p)*ncon((B,Ar,np.conj(Al),hTilde),([4,3,1],[1,2,-3],[4,5,-1],[5,-2,3,2]))+\\\n",
    "            1*ncon((Al,B,np.conj(Al),hTilde),([4,3,1],[1,2,-3],[4,5,-1],[5,-2,3,2]))+\\\n",
    "            np.exp(1j*p)*ncon((Al,Al,np.conj(Al),right,hTilde),([1,2,4],[4,5,6],[1,3,-1],[6,-3],[3,-2,2,5]))+\\\n",
    "            np.exp(2*1j*p)*ncon((Al,Al,np.conj(Ar),right,hTilde),([-1,6,5],[5,3,2],[-3,4,1],[2,1],[-2,4,6,3]))+\\\n",
    "            1*ncon((Lh,B),([-1,1],[1,-2,-3]))+\\\n",
    "            1*ncon((B,Rh),([-1,-2,1],[1,-3]))+\\\n",
    "            np.exp(-1j*p)*ncon((left,Ar),([-1,1],[1,-2,-3]))+\\\n",
    "            np.exp(+1j*p)*ncon((Lh,Al,right),([-1,1],[1,-2,2],[2,-3]))\n",
    "            \n",
    "        y = ncon((y, np.conj(Vl)), ([1, 2, -2], [1, 2, -1]))\n",
    "        y = y.reshape(-1)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    # find reduced parametrization\n",
    "    L = np.reshape(np.moveaxis(np.conj(Al), -1, 0), (D, D*d))\n",
    "    Vl = np.reshape(null_space(L), (D, d, D*(d-1)))\n",
    "    handleHeff = LinearOperator((D**2*(d-1), D**2*(d-1)), matvec=lambda x: ApplyHeff(x))\n",
    "    e, x = eigs(handleHeff, k=num, which='SR')\n",
    "    \n",
    "    return x, e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to compute the Haldane gap on top of the ground state of the spin-1 Heisenberg antiferromagnet we have just obtained using VUMPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.pi\n",
    "num = 3;\n",
    "x, e = quasiParticle(h, Al, Ar, Ac, C, p, num)\n",
    "print('First triplet: {}'.format(', '.join(str(v.real) for v in e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
